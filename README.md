# Traffic World Model - å¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹

åŸºäºTransformerçš„æ½œåœ¨ä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºå¤šç«™ç‚¹æ— äººæœºè½¨è¿¹æ•°æ®çš„é¢„æµ‹å’Œä»¿çœŸã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```bash
pip install -r requirements.txt
```

**ä¾èµ–**: Python 3.10+, PyTorch 2.0+, NumPy, Pandas, PyYAML

### 2. æ•°æ®å‡†å¤‡

å°†CSVæ–‡ä»¶æŒ‰ç«™ç‚¹ç»„ç»‡ï¼š

```
data/raw/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ drone_1.csv
â”‚   â”œâ”€â”€ drone_2.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ B/
â”‚   â””â”€â”€ ...
...
â””â”€â”€ I/
```

**CSVå¿…éœ€åˆ—**: `track_id`, `frame`, `center_x`, `center_y`, `angle`, `class_id`
**å¯é€‰åˆ—**: `lane`, `preceding_id`, `following_id`, `timestamp`

### 3. æ•°æ®é¢„å¤„ç†

```bash
python preprocess_multisite.py
```

**è¾“å‡º**:
- `data/processed/train_episodes.npz`
- `data/processed/val_episodes.npz`
- `data/processed/test_episodes.npz`
- `data/processed/metadata.json`

**é»˜è®¤é…ç½®**:
- Episodeé•¿åº¦: T=80 (C=65 context + H=15 rollout)
- Stride: 15 frames (0.5ç§’ @ 30 FPS)
- Split: 70% train / 15% val / 15% test (chronological)
- Features: 12-dim (position, velocity, acceleration, angle, class, lane, preceding/following, site_id)

### 4. éªŒè¯æ•°æ®

```bash
python validate_preprocessing.py
```

**æ£€æŸ¥é¡¹**:
- âœ“ Metadataä¸€è‡´æ€§ (fps=30, T=80, C=65, H=15)
- âœ“ Lane tokensæ ¼å¼ ("site:lane")
- âœ“ Splitæ—¶é—´ä¸é‡å 
- âœ“ Feature dimensions

### 5. è®­ç»ƒæ¨¡å‹

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 12 \
    --latent_dim 256 \
    --batch_size 32 \
    --n_epochs 100
```

**è®­ç»ƒç›‘æ§**: æ—¥å¿—ä¿å­˜åœ¨ `logs/trainer.log`

---

## ğŸ“– è¯¦ç»†è¯´æ˜

### æ•°æ®é¢„å¤„ç†æµç¨‹

é¢„å¤„ç†pipelineå®ç°äº†ä»¥ä¸‹å…³é”®æ”¹è¿›ï¼š

**1. Per-Site Global Timeline**
- æ¯ä¸ªç«™ç‚¹çš„æ‰€æœ‰CSVæ–‡ä»¶åˆå¹¶ä¸ºç»Ÿä¸€æ—¶é—´è½´
- å¤„ç†frameé‡ç½®å’Œtrack_idå†²çª
- åˆ›å»º`global_frame`å’Œ`global_track_id`

**2. Gap Detection & Segmentation**
- è‡ªåŠ¨æ£€æµ‹æ—¶é—´é—´éš™ï¼ˆgap > 1 frameï¼‰
- å°†timelineåˆ†å‰²ä¸ºè¿ç»­æ®µ
- Episodesä¸è·¨è¶Šæ—¶é—´æ–­ç‚¹

**3. Fixed-Stride Episode Extraction**
- T=80 frames per episode
- S=15 frames stride (equal interval sampling)
- Stable vehicle-to-slot assignment

**4. Site-Specific Lane Encoding**
- Lane tokensæ ¼å¼: "A:A1", "B:crossroads1"
- é¿å…è·¨ç«™ç‚¹laneå†²çª
- åŠ¨æ€è®¡ç®—num_lanes

**5. Chronological Split (Scheme A)**
- å…ˆç¡®å®šframe cutoffs (70%/15%/15%)
- åœ¨å„splitå†…ç‹¬ç«‹æå–episodes
- çœŸæ­£çš„æ—¶é—´ä¸é‡å ï¼Œæ— temporal leakage

**Feature Layout (12-dim)**:
```
[0]  center_x        â†’ continuous
[1]  center_y        â†’ continuous
[2]  vx              â†’ continuous
[3]  vy              â†’ continuous
[4]  ax              â†’ continuous
[5]  ay              â†’ continuous
[6]  angle           â†’ continuous
[7]  class_id        â†’ discrete (do not normalize)
[8]  lane_id         â†’ discrete (do not normalize, use embedding)
[9]  has_preceding   â†’ binary
[10] has_following   â†’ binary
[11] site_id         â†’ discrete (do not normalize, use embedding)
```

### é¢„å¤„ç†å‚æ•°

```bash
python preprocess_multisite.py \
    --episode_length 80 \        # T = C + H
    --stride 15 \                # Step between episodes
    --fps 30.0 \                 # Frames per second
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15 \
    --use_chronological_split    # Time-based split (default)
```

### æ¨¡å‹æ¶æ„

**Encoder** (Multi-Agent Transformer):
- Feature embedding + site/lane embeddings
- Spatial positional encoding (optional)
- Social pooling (optional)
- Transformer attention over agents
- Masked mean pooling â†’ latent

**Dynamics** (GRU/LSTM/Transformer):
- 1-step transition: latent[t] â†’ latent[t+1]
- Teacher-forced during training
- Open-loop rollout during evaluation

**Decoder**:
- Latent â†’ states reconstruction
- Existence prediction (which agents are present)

**Loss**:
- Reconstruction: L2(states_t, reconstructed_t)
- Prediction: L2(states_{t+1}, predicted_{t+1})
- Existence: BCE(masks, predicted_masks)

### è®­ç»ƒå‚æ•°

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 12 \              # Must match metadata.n_features
    --latent_dim 256 \
    --dynamics_type gru \         # gru/lstm/transformer
    --batch_size 32 \
    --n_epochs 100 \
    --learning_rate 1e-3 \
    --recon_weight 1.0 \
    --pred_weight 1.0 \
    --existence_weight 0.1
```

**é‡è¦**: `--input_dim` å¿…é¡»ä¸ `metadata.json` ä¸­çš„ `n_features` ä¸€è‡´ï¼

### ä½¿ç”¨Laneå’ŒSite Embeddings

åœ¨encoderä¸­å¯ç”¨embeddingsï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰ï¼š

```python
encoder = MultiAgentEncoder(
    input_dim=12,
    use_site_id=True,
    num_sites=9,
    site_embed_dim=16,
    use_lane_embedding=True,
    num_lanes=len(lane_mapping) + 1,  # ä»metadataè¯»å–
    lane_embed_dim=16,
    lane_feature_idx=8,
)
```

**æ³¨æ„**: ç¦»æ•£ç‰¹å¾(lane_id, class_id, site_id)ä¸è¦z-score normalizeï¼

---

## ğŸ“Š æ•°æ®æ ¼å¼

### NPZæ–‡ä»¶ç»“æ„

```python
{
    'states': [N, T, K, F],      # N episodes, T=80 timesteps, K=50 max agents, F=12 features
    'masks': [N, T, K],          # 1=real agent, 0=padding
    'scene_ids': [N],            # Site ID per episode
    'start_frames': [N],         # Episode start global_frame
    'end_frames': [N]            # Episode end global_frame
}
```

### Metadata.jsonå…³é”®å­—æ®µ

```json
{
  "n_features": 12,
  "episode_length": 80,
  "context_length": 65,
  "rollout_horizon": 15,
  "stride": 15,
  "fps": 30.0,
  "dt": 0.033333,
  "use_chronological_split": true,
  "lane_mapping": {
    "A:A1": 1,
    "A:B1": 2,
    "B:crossroads1": 3,
    ...
  },
  "validation_info": {
    "num_lanes": 150,
    "discrete_features": {
      "lane_id": 8,
      "class_id": 7,
      "site_id": 11
    },
    "do_not_normalize": ["lane_id", "class_id", "site_id"]
  }
}
```

---

## ğŸ” éªŒè¯æ£€æŸ¥æ¸…å•

è¿è¡Œ `python validate_preprocessing.py` ä¼šæ£€æŸ¥ï¼š

- [x] fps=30, dt=1/30
- [x] episode_length=80, stride=15
- [x] context_length=65, rollout_horizon=15
- [x] Lane tokensæ ¼å¼: "site:lane"
- [x] Feature dimensionsåŒ¹é…
- [x] Train/val/testæ—¶é—´ä¸é‡å 
- [x] Discrete featuresæ­£ç¡®æ ‡æ³¨

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
traffic_wm/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # åŸå§‹CSV (ç”¨æˆ·æä¾›)
â”‚   â”‚   â”œâ”€â”€ A/
â”‚   â”‚   â”œâ”€â”€ B/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ processed/        # é¢„å¤„ç†è¾“å‡º
â”‚       â”œâ”€â”€ train_episodes.npz
â”‚       â”œâ”€â”€ val_episodes.npz
â”‚       â”œâ”€â”€ test_episodes.npz
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocess.py        # æ ¸å¿ƒé¢„å¤„ç†é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ split_strategy.py    # Chronological split
â”‚   â”‚   â””â”€â”€ dataset.py           # PyTorch Dataset
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ encoder.py           # Multi-Agent Encoder
â”‚   â”‚   â”œâ”€â”€ decoder.py           # Decoder
â”‚   â”‚   â”œâ”€â”€ dynamics.py          # GRU/LSTM/Transformer
â”‚   â”‚   â””â”€â”€ world_model.py       # Complete model
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_world_model.py # è®­ç»ƒè„šæœ¬
â”‚   â”‚   â””â”€â”€ losses.py            # Loss functions
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ rollout_eval.py      # Rollout evaluation
â”‚   â”‚   â”œâ”€â”€ prediction_metrics.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ common.py
â”‚
â”œâ”€â”€ preprocess_multisite.py      # é¢„å¤„ç†ä¸»è„šæœ¬
â”œâ”€â”€ validate_preprocessing.py    # éªŒè¯è„šæœ¬
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. Input DimensionåŒ¹é…

**æœ€å¸¸è§é”™è¯¯**: `--input_dim` ä¸é¢„å¤„ç†ä¸åŒ¹é…

```bash
# å…ˆæ£€æŸ¥
cat data/processed/metadata.json | grep n_features
# è¾“å‡º: "n_features": 12

# ç„¶åè®­ç»ƒæ—¶ä½¿ç”¨ç›¸åŒå€¼
python src/training/train_world_model.py --input_dim 12 ...
```

### 2. æ—¶é—´å‚æ•°ä¸€è‡´æ€§

- **Raw data**: 30 FPS
- **Preprocessing**: `--fps 30.0`
- **Episodes**: T=80 frames = 2.67ç§’
- **Context (C)**: 65 frames = 2.17ç§’
- **Rollout (H)**: 15 frames = 0.50ç§’

### 3. Chronological Split

**é»˜è®¤å¯ç”¨**ï¼Œç¡®ä¿train/val/teståœ¨æ—¶é—´ä¸Šä¸é‡å ã€‚

å¦‚éœ€éšæœºsplitï¼ˆä¸æ¨èï¼‰ï¼š
```bash
python preprocess_multisite.py --use_random_split
```

### 4. Lane Embedding

Lane tokensæ ¼å¼: `"site:lane"`
- âœ“ Correct: `"A:A1"`, `"B:crossroads1"`
- âœ— Wrong: `"A1"`, `"crossroads1"`

éªŒè¯: `cat data/processed/metadata.json | grep lane_mapping`

---

## ğŸ› å¸¸è§é—®é¢˜

**Q: é¢„å¤„ç†åval/testæ²¡æœ‰episodesï¼Ÿ**
A: æ•°æ®é‡å¤ªå°ã€‚è‡ªåŠ¨è¾¹ç•Œè°ƒæ•´ä¼šç¡®ä¿è‡³å°‘ `episode_length + stride` å¸§ã€‚

**Q: è®­ç»ƒæ—¶ç»´åº¦ä¸åŒ¹é…ï¼Ÿ**
A: æ£€æŸ¥ `--input_dim` æ˜¯å¦ä¸ `metadata.json` çš„ `n_features` ä¸€è‡´ã€‚

**Q: Lane IDå†²çªï¼Ÿ**
A: ç¡®ä¿é¢„å¤„ç†ä½¿ç”¨äº†site-specific tokens (`"A:lane"`)ã€‚è¿è¡Œ `validate_preprocessing.py` æ£€æŸ¥ã€‚

**Q: æ—¶é—´æ³„æ¼é—®é¢˜ï¼Ÿ**
A: ä½¿ç”¨ `--use_chronological_split` (é»˜è®¤)ã€‚è¿è¡Œ `validate_preprocessing.py` éªŒè¯æ—¶é—´ä¸é‡å ã€‚

**Q: å¦‚ä½•å¯è§†åŒ–ç»“æœï¼Ÿ**
A: ä½¿ç”¨ `src/evaluation/visualization.py` (éœ€è‡ªè¡Œå®ç°rollout evaluation)

---

## ğŸ“ å®Œæ•´å·¥ä½œæµç¨‹

```bash
# 1. å‡†å¤‡æ•°æ®
# å°†CSVæ–‡ä»¶æ”¾å…¥ data/raw/A/, data/raw/B/, ...

# 2. é¢„å¤„ç†
python preprocess_multisite.py

# 3. éªŒè¯
python validate_preprocessing.py

# 4. æ£€æŸ¥é…ç½®
cat data/processed/metadata.json

# 5. è®­ç»ƒ
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 12 \
    --latent_dim 256 \
    --batch_size 32 \
    --n_epochs 100

# 6. ç›‘æ§è®­ç»ƒ
tail -f logs/trainer.log

# 7. (å¯é€‰) Rollout evaluation
# éœ€å®ç° src/evaluation/rollout_eval.py
```

---

## ğŸ¯ Pipelineç‰¹æ€§æ€»ç»“

| ç‰¹æ€§ | å®ç°æ–¹å¼ |
|------|---------|
| **Multi-site handling** | Per-site global timeline, site_id embedding |
| **Frame resets** | global_frame = frame + file_offset |
| **Track ID collisions** | global_track_id = file_id * 1M + track_id |
| **Gap detection** | Split when gap > 1 frame |
| **Episode extraction** | Fixed-stride (T=80, S=15) |
| **Lane encoding** | Site-specific tokens ("A:A1") |
| **Split strategy** | Chronological (time-based) |
| **Temporal leakage** | Scheme A: frame cutoffs â†’ independent extraction |
| **Validation** | Automated checks via validate_preprocessing.py |

---

## ğŸ“š å‚è€ƒ

- **improved.md**: åŸå§‹æ”¹è¿›è§„èŒƒ
- **IMPROVEMENTS_todo.md**: è¯¦ç»†éœ€æ±‚æ¸…å•
- **BUGFIX_PATCH.md**: Bugä¿®å¤è¯´æ˜

**æ‰€æœ‰æ”¹è¿›å·²å®æ–½ï¼Œä»£ç å·²éªŒè¯å¯ç”¨ï¼** âœ…

---

**License**: MIT
**Author**: Traffic World Model Team
**Last Updated**: 2025-12-12
