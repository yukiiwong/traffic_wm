# Traffic World Model - å¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹

åŸºäºTransformerçš„æ½œåœ¨ä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºå¤šç«™ç‚¹æ— äººæœºè½¨è¿¹æ•°æ®çš„é¢„æµ‹å’Œä»¿çœŸã€‚

**æ ¸å¿ƒç‰¹æ€§**:
- ğŸš å¤šç«™ç‚¹æ— äººæœºæ•°æ®æ”¯æŒ (Sites A-I)
- ğŸ§  Transformerç¼–ç å™¨ + Transformeræ—¶åºåŠ¨åŠ›å­¦ + ç‰©ç†å…ˆéªŒ
- ğŸ¯ 12ç»´ç‰¹å¾ + Site/Lane/Class embeddings
- â±ï¸ æ—¶åºæ— é‡å çš„train/val/teståˆ’åˆ†
- ğŸ”§ å®Œæ•´çš„é¢„å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°æµç¨‹

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
2. [æ•°æ®é¢„å¤„ç†](#-æ•°æ®é¢„å¤„ç†)
3. [æ¨¡å‹è®­ç»ƒ](#-æ¨¡å‹è®­ç»ƒ)
4. [æ¨¡å‹è¯„ä¼°](#-æ¨¡å‹è¯„ä¼°)
5. [å¯è§†åŒ–](#-å¯è§†åŒ–)
6. [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
7. [ä»£ç æ–‡ä»¶è¯¦è§£](#-ä»£ç æ–‡ä»¶è¯¦è§£)
8. [é‡è¦è¯´æ˜](#-é‡è¦è¯´æ˜)
9. [æ•…éšœæ’æŸ¥](#-æ•…éšœæ’æŸ¥)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå®‰è£…

```bash
# Python 3.10+
pip install -r requirements.txt
```

**æ ¸å¿ƒä¾èµ–**:
- PyTorch >= 2.0.0
- NumPy >= 1.24.0
- Pandas >= 2.0.0
- tqdm, matplotlib, seaborn, opencv-python

### å®Œæ•´æµç¨‹ï¼ˆ4æ­¥ï¼‰

```bash
# 1. æ•°æ®é¢„å¤„ç†
python preprocess_multisite.py

# 2. éªŒè¯æ•°æ®
python validate_preprocessing.py

# 3. è®­ç»ƒæ¨¡å‹
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 12 \
    --latent_dim 256 \
    --batch_size 16 \
    --epochs 50 \
    --lr 3e-4

# 4. è¯„ä¼°æ¨¡å‹
python src/evaluation/rollout_eval.py \
    --checkpoint checkpoints/best_model.pt \
    --test_data data/processed/test_episodes.npz \
    --context_length 65 \
    --rollout_horizon 15
```

---

## ğŸ“Š æ•°æ®é¢„å¤„ç†

### æ­¥éª¤1: æ•°æ®å‡†å¤‡

**è¾“å…¥æ•°æ®ç»“æ„**:
```
data/raw/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ drone_1.csv
â”‚   â”œâ”€â”€ drone_2.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ B/
â”‚   â”œâ”€â”€ drone_1.csv
â”‚   â””â”€â”€ ...
...
â””â”€â”€ I/
    â””â”€â”€ ...
```

**CSVå¿…éœ€åˆ—**:
- `track_id`: è½¦è¾†ID
- `frame`: å¸§å·
- `center_x`, `center_y`: ä¸­å¿ƒåæ ‡
- `angle`: æœå‘è§’åº¦
- `class_id`: è½¦è¾†ç±»åˆ«

**å¯é€‰åˆ—**:
- `lane`: è½¦é“ID
- `preceding_id`, `following_id`: å‰åè½¦ID
- `timestamp`: æ—¶é—´æˆ³

### æ­¥éª¤2: è¿è¡Œé¢„å¤„ç†

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**:
- ğŸ“„ **ä¸»è„šæœ¬**: `preprocess_multisite.py`
- ğŸ“„ **æ ¸å¿ƒé€»è¾‘**: `src/data/preprocess.py`
- ğŸ“„ **æ•°æ®åˆ’åˆ†**: `src/data/split_strategy.py`

**å‘½ä»¤**:
```bash
# é»˜è®¤é…ç½®ï¼ˆæ¨èï¼‰
python preprocess_multisite.py

# è‡ªå®šä¹‰å‚æ•°
python preprocess_multisite.py \
    --raw_data_dir data/raw \
    --output_dir data/processed \
    --episode_length 80 \
    --stride 15 \
    --fps 30.0 \
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15
```

**å¤„ç†æµç¨‹**:

```
preprocess_multisite.py
  â†“ è°ƒç”¨
src/data/preprocess.py
  â”œâ”€ build_global_timeline()          # 1. æ„å»ºæ¯ä¸ªsiteçš„å…¨å±€æ—¶é—´çº¿
  â”‚   â””â”€ åˆå¹¶æ‰€æœ‰CSV, å¤„ç†frameé‡ç½®
  â”‚
  â”œâ”€ detect_gaps_and_split_segments() # 2. æ£€æµ‹æ—¶åºgapå¹¶åˆ†æ®µ
  â”‚   â””â”€ ç¡®ä¿episodesä¸è·¨è¶Šgap
  â”‚
  â”œâ”€ extract_fixed_stride_episodes()  # 3. å›ºå®šæ­¥é•¿æå–episodes
  â”‚   â””â”€ T=80å¸§, stride=15å¸§
  â”‚
  â”œâ”€ encode_lane()                     # 4. ç¼–ç laneä¸ºsite-specific token
  â”‚   â””â”€ "A:A1", "B:crossroads1"ç­‰
  â”‚
  â””â”€ extract_extended_features()       # 5. æå–12ç»´ç‰¹å¾
      â”œâ”€ center_x, center_y (æ ‡å‡†åŒ–)
      â”œâ”€ vx, vy (é€Ÿåº¦)
      â”œâ”€ ax, ay (åŠ é€Ÿåº¦)
      â”œâ”€ angle (æœå‘)
      â”œâ”€ class_id (ç¦»æ•£, ä¸æ ‡å‡†åŒ–)
      â”œâ”€ lane_id (ç¦»æ•£, ä¸æ ‡å‡†åŒ–)
      â”œâ”€ has_preceding, has_following
      â””â”€ site_id (ç¦»æ•£, ä¸æ ‡å‡†åŒ–)
  â†“
src/data/split_strategy.py
  â””â”€ chronological_split_episodes()    # 6. æ—¶åºåˆ’åˆ†
      â””â”€ æŒ‰æ—¶é—´é¡ºåºåˆ†train/val/test
```

**è¾“å‡ºæ–‡ä»¶**:
```
data/processed/
â”œâ”€â”€ train_episodes.npz               # [N_train, 80, 50, 12]
â”‚   â”œâ”€â”€ 'states'        â†’ [N, T, K, F] çŠ¶æ€çŸ©é˜µ
â”‚   â”œâ”€â”€ 'masks'         â†’ [N, T, K] æœ‰æ•ˆæ€§mask
â”‚   â”œâ”€â”€ 'scene_ids'     â†’ [N] site ID
â”‚   â”œâ”€â”€ 'start_frames'  â†’ [N] episodeèµ·å§‹å¸§
â”‚   â””â”€â”€ 'end_frames'    â†’ [N] episodeç»“æŸå¸§
â”‚
â”œâ”€â”€ val_episodes.npz                 # åŒä¸Š
â”œâ”€â”€ test_episodes.npz                # åŒä¸Š
â”‚
â”œâ”€â”€ metadata.json                    # å…ƒæ•°æ®
â”‚   â”œâ”€â”€ n_features: 12
â”‚   â”œâ”€â”€ episode_length: 80
â”‚   â”œâ”€â”€ context_length: 65
â”‚   â”œâ”€â”€ rollout_horizon: 15
â”‚   â”œâ”€â”€ fps: 30.0
â”‚   â”œâ”€â”€ feature_layout: {...}
â”‚   â”œâ”€â”€ lane_mapping: {...}
â”‚   â””â”€â”€ validation_info: {
â”‚       â”œâ”€â”€ discrete_features: {7, 8, 11}
â”‚       â””â”€â”€ do_not_normalize: [...]
â”‚   }
â”‚
â””â”€â”€ split_config.json                # åˆ’åˆ†é…ç½®
    â”œâ”€â”€ train_files: [...]
    â”œâ”€â”€ val_files: [...]
    â””â”€â”€ test_files: [...]
```

**é‡è¦å‚æ•°**:
- `T=80`: Episodeé•¿åº¦ (80å¸§ â‰ˆ 2.67ç§’ @ 30 FPS)
- `C=65`: Contexté•¿åº¦ (warm-up, å‰65å¸§)
- `H=15`: Rollout horizon (é¢„æµ‹å15å¸§)
- `K=50`: æœ€å¤§è½¦è¾†æ•°ï¼ˆpaddingï¼‰
- `F=12`: ç‰¹å¾ç»´åº¦

### æ­¥éª¤3: ç‰¹å¾è¯´æ˜

é¢„å¤„ç†ç”Ÿæˆ**12ç»´ç‰¹å¾å‘é‡** (`src/data/preprocess.py:extract_extended_features()`):

| ç´¢å¼• | ç‰¹å¾å | ç±»å‹ | è¯´æ˜ | ä»£ç ä½ç½® |
|------|--------|------|------|---------|
| 0 | center_x | è¿ç»­ | Xåæ ‡ï¼ˆz-scoreæ ‡å‡†åŒ–ï¼‰ | `extract_extended_features()` L385 |
| 1 | center_y | è¿ç»­ | Yåæ ‡ï¼ˆz-scoreæ ‡å‡†åŒ–ï¼‰ | L386 |
| 2 | vx | è¿ç»­ | Xæ–¹å‘é€Ÿåº¦ | L388 |
| 3 | vy | è¿ç»­ | Yæ–¹å‘é€Ÿåº¦ | L389 |
| 4 | ax | è¿ç»­ | Xæ–¹å‘åŠ é€Ÿåº¦ | L390 |
| 5 | ay | è¿ç»­ | Yæ–¹å‘åŠ é€Ÿåº¦ | L391 |
| 6 | angle | è¿ç»­ | æœå‘è§’åº¦ | L392 |
| 7 | class_id | **ç¦»æ•£** | è½¦è¾†ç±»åˆ«ï¼ˆä¸æ ‡å‡†åŒ–ï¼‰ | L393 |
| 8 | lane_id | **ç¦»æ•£** | è½¦é“IDï¼ˆä¸æ ‡å‡†åŒ–ï¼‰ | L394 |
| 9 | has_preceding | äºŒå€¼ | æ˜¯å¦æœ‰å‰è½¦ | L395 |
| 10 | has_following | äºŒå€¼ | æ˜¯å¦æœ‰åè½¦ | L396 |
| 11 | site_id | **ç¦»æ•£** | ç«™ç‚¹ID 0-8ï¼ˆä¸æ ‡å‡†åŒ–ï¼‰ | L397 |

**å…³é”®**:
- âœ… **è¿ç»­ç‰¹å¾** (0-6, 9-10): z-scoreæ ‡å‡†åŒ– (mean~0, std~1)
- âŒ **ç¦»æ•£ç‰¹å¾** (7, 8, 11): **ä¸è¿›è¡Œæ ‡å‡†åŒ–**ï¼Œä¿æŒåŸå§‹æ•´æ•°å€¼
- ç¦»æ•£ç‰¹å¾ç”¨äºembeddingï¼Œå¿…é¡»ä¿æŒæ•´æ•°å½¢å¼

### æ­¥éª¤4: éªŒè¯é¢„å¤„ç†ç»“æœ

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**:
- ğŸ“„ **éªŒè¯è„šæœ¬**: `validate_preprocessing.py`

**å‘½ä»¤**:
```bash
python validate_preprocessing.py
```

**æ£€æŸ¥é¡¹**:
```python
# validate_preprocessing.py æ£€æŸ¥:
âœ… 1. å…ƒæ•°æ®ä¸€è‡´æ€§ (fps=30, T=80, C=65, H=15)
âœ… 2. Lane tokenæ ¼å¼ ("site:lane")
âœ… 3. Train/Val/Testæ—¶åºæ— é‡å 
âœ… 4. ç¦»æ•£ç‰¹å¾æœªè¢«æ ‡å‡†åŒ–
âœ… 5. ç‰¹å¾ç»´åº¦æ­£ç¡® (F=12)
âœ… 6. Episodeæ•°é‡åˆç†
```

**æœŸæœ›è¾“å‡º**:
```
âœ… All preprocessing checks passed!
- Metadata: fps=30.0, T=80, C=65, H=15
- Features: 12 (9 continuous, 3 discrete)
- Lane tokens: site:lane format OK
- Splits: No temporal overlap
- Train: 44100 episodes
- Val: 6300 episodes
- Test: 6300 episodes
```

---

## ğŸ“ æ¨¡å‹è®­ç»ƒ

### æ­¥éª¤1: è®­ç»ƒå‰å‡†å¤‡

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**:
- ğŸ“„ **ä¸»è®­ç»ƒè„šæœ¬**: `src/training/train_world_model.py`
- ğŸ“„ **Losså‡½æ•°**: `src/training/losses.py`
- ğŸ“„ **DatasetåŠ è½½**: `src/data/dataset.py`
- ğŸ“„ **æ¨¡å‹å®šä¹‰**: `src/models/world_model.py`
  - ğŸ“„ Encoder: `src/models/encoder.py`
  - ğŸ“„ Dynamics: `src/models/dynamics.py`
  - ğŸ“„ Decoder: `src/models/decoder.py`

**æ£€æŸ¥å…ƒæ•°æ®**:
```bash
cat data/processed/metadata.json | grep n_features
# è¾“å‡º: "n_features": 12
```

### æ­¥éª¤2: è®­ç»ƒå‘½ä»¤

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --checkpoint_dir checkpoints/world_model \
    --input_dim 12 \
    --latent_dim 256 \
    --batch_size 16 \
    --epochs 50 \
    --lr 3e-4 \
    --weight_decay 1e-4 \
    --grad_clip 1.0
```

**å…³é”®å‚æ•°**:
- `--input_dim 12`: **å¿…é¡»ä¸metadata.jsonä¸­çš„n_featuresä¸€è‡´**
- `--latent_dim 256`: æ½œåœ¨ç©ºé—´ç»´åº¦ï¼ˆæ¨è128-512ï¼‰
- `--batch_size 16`: æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼ˆé»˜è®¤16ï¼‰
- `--epochs 50`: è®­ç»ƒè½®æ•°
- `--lr 3e-4`: å­¦ä¹ ç‡ï¼ˆAdamWä¼˜åŒ–å™¨ï¼‰
- `--dynamics_layers 4`: TransformeråŠ¨åŠ›å­¦å±‚æ•°
- `--dynamics_heads 8`: æ³¨æ„åŠ›å¤´æ•°
- `--max_dynamics_len 512`: æœ€å¤§åºåˆ—é•¿åº¦
- `--max_dynamics_context 128`: Rolloutæ—¶çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦

### æ­¥éª¤3: æ¨¡å‹æ¶æ„è¯¦è§£

**æ•´ä½“æ¶æ„**: Encoder â†’ Transformer Dynamics â†’ Decoder (with Kinematic Prior)

**å®Œæ•´çš„å‰å‘ä¼ æ’­æµç¨‹**:

```
è¾“å…¥: states [B, T=80, K=50, F=12], masks [B, T, K]
  â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€src/models/encoder.py: MultiAgentEncoderã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  1. ç‰¹å¾åˆ†ç¦» (forward L133-164)
     # å°†12ç»´ç‰¹å¾åˆ†ä¸ºè¿ç»­å’Œç¦»æ•£ç‰¹å¾

     è¿ç»­ç‰¹å¾æå– (L139):
     â”œâ”€ continuous_indices = [0,1,2,3,4,5,6,9,10]  # æ’é™¤7,8,11
     â””â”€ cont = states[..., continuous_indices]  # [B, T, K, 9]

     ç¦»æ•£ç‰¹å¾embedding (L145-161):
     â”œâ”€ lane_id [8] â†’ lane_embedding(nn.Embedding(num_lanes, 16))
     â”œâ”€ class_id [7] â†’ class_embedding(nn.Embedding(num_classes, 8))  # â† æ–°å¢
     â””â”€ site_id [11] â†’ site_embedding(nn.Embedding(num_sites, 8))

  2. è¿ç»­ç‰¹å¾æŠ•å½± (L69-74)
     cont_emb = continuous_projector(cont)
     # Sequential(Linear(9â†’256), LayerNorm, ReLU, Dropout)
     â†’ [B, T, K, hidden_dim=256]

  3. ç‰¹å¾èåˆ (L92-96, L163)
     fused_dim = 256 + 16 + 8 + 8 = 288
     agent_feats = concat([cont_emb, lane_emb, class_emb, site_emb])  # [B,T,K,288]
     agent_feats = fusion(agent_feats)  # Linear(288â†’256) + ReLU
     â†’ [B, T, K, hidden_dim=256]

  4. Transformer Attention over Agents (L98-106, L169)
     # å¯¹æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹å¤„ç†ï¼Œåœ¨agentç»´åº¦Kä¸Šåšattention
     states_flat = states.reshape(B*T, K, F)  # [B*T, K, 256]

     for layer in transformer_layers:  # n_layers=2
         agent_feats = TransformerEncoderLayer(
             agent_feats,
             src_key_padding_mask=pad  # [B*T, K] maskæ— æ•ˆagent
         )
     â†’ [B*T, K, hidden_dim=256]

  5. Masked Mean Pooling (L172-173)
     # èšåˆKä¸ªagentåˆ°å•ä¸€åœºæ™¯è¡¨ç¤º
     weights = masks_flat.unsqueeze(-1)  # [B*T, K, 1]
     pooled = (agent_feats * weights).sum(dim=1) / weights.sum(dim=1).clamp(min=1e-6)
     â†’ [B*T, hidden_dim=256]

  6. æŠ•å½±åˆ°Latentç©ºé—´ (L108-111, L175)
     latent = to_latent(pooled)  # Linear(256â†’256) + LayerNorm
     latent = latent.view(B, T, latent_dim)
     â†’ [B, T, latent_dim=256]
  â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€src/models/dynamics.py: LatentDynamics (Transformer-only)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  âš ï¸ é‡è¦å˜åŒ–: ç°åœ¨åªæ”¯æŒTransformerï¼Œç§»é™¤äº†GRU/LSTMé€‰é¡¹

  1. ä½ç½®ç¼–ç  (forward L45-49, L114)
     pos_emb: å¯å­¦ä¹ å‚æ•° [1, max_len=512, latent_dim=256]
     (æˆ–ä½¿ç”¨sinusoidal positional encoding)

     x = latent + pos_emb[:, :T, :]  # æ·»åŠ ä½ç½®ä¿¡æ¯
     â†’ [B, T, D]

  2. Causal Transformer (L51-59, L78-86, L116-122)
     # å› æœmaskç¡®ä¿æ—¶é—´æ­¥tåªèƒ½attendåˆ°<=tçš„å†å²
     causal_mask = _causal_mask(T, device, dtype)  # [T, T]
     # Upper triangular (excluding diagonal) = -inf

     out = transformer(
         x,
         mask=causal_mask,  # å› æœmask
         src_key_padding_mask=time_padding_mask  # [B,T] å¯é€‰padding mask
     )
     # TransformerEncoder:
     #   - n_layers=4
     #   - n_heads=8
     #   - dim_feedforward=1024 (4*latent_dim)
     #   - norm_first=True (Pre-LN)
     â†’ [B, T, D]

  3. OutputæŠ•å½± (L62-65, L124)
     predicted_latent = output_proj(out)
     # Sequential(LayerNorm, Linear(Dâ†’D))
     â†’ [B, T, latent_dim=256]

  4. å•æ­¥é¢„æµ‹æ–¹æ³• (step L127-154)
     # Rolloutæ—¶ä½¿ç”¨ï¼Œæ”¯æŒtruncated context
     next_latent = step(latent_history, max_context=128)
     # åªç”¨æœ€è¿‘128æ­¥å†å²æ¥é¢„æµ‹ä¸‹ä¸€æ­¥ï¼ˆæ•ˆç‡ä¼˜åŒ–ï¼‰
  â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€src/models/decoder.py: StateDecoderã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  âš ï¸ é‡è¦æ–°å¢: (x,y)æ®‹å·®å¤´ï¼Œç”¨äºç‰©ç†å…ˆéªŒä¿®æ­£

  1. MLP Backbone (forward L34-42, L81)
     h = backbone(latent)
     # Sequential(
     #   Linear(256â†’256), LayerNorm, ReLU, Dropout,
     #   Linear(256â†’256), ReLU, Dropout
     # )
     â†’ [B, T, hidden_dim=256]

  2. ç»å¯¹çŠ¶æ€é¢„æµ‹ (L45, L83)
     states = state_head(h).view(B, T, K=50, F=12)
     # Linear(256 â†’ 50*12=600)
     â†’ [B, T, K, F]

  3. Existence Logits (L48, L84)
     existence_logits = existence_head(h)
     # Linear(256 â†’ 50)
     â†’ [B, T, K]

  4. (x,y)æ®‹å·®å¤´ (L51-57, L86-90) â† æ–°å¢
     IF enable_xy_residual:
         residual_xy = residual_xy_head(h).view(B, T, K, 2)
         # Linear(256 â†’ 50*2=100)
         # âœ… åˆå§‹åŒ–ä¸º0 (ä»çº¯ç‰©ç†å…ˆéªŒå¼€å§‹å­¦ä¹ )
         â†’ [B, T, K, 2]
  â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€src/models/world_model.py: WorldModelã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  âš ï¸ æ ¸å¿ƒåˆ›æ–°: Kinematic Prior + Residual

  å®Œæ•´æµç¨‹ (forward L173-215):

  1. ç¼–ç  (L190)
     latent = encoder(states, masks)  # [B, T, D]

  2. æ—¶é—´padding mask (L193)
     time_padding = (masks.sum(dim=-1) == 0)  # [B,T] bool
     # Trueè¡¨ç¤ºè¯¥æ—¶é—´æ­¥æ‰€æœ‰agentéƒ½ä¸å­˜åœ¨

  3. åŠ¨åŠ›å­¦é¢„æµ‹ (L195)
     predicted_latent, _ = dynamics(latent, time_padding_mask=time_padding)
     â†’ [B, T, D]

  4. è§£ç é‡å»ºåˆ†æ”¯ (L197)
     recon_states, exist_logits, _ = decoder(latent, return_residual_xy=False)
     # ä¸ä½¿ç”¨residual_xyï¼Œç›´æ¥è¾“å‡ºç»å¯¹çŠ¶æ€

  5. è§£ç é¢„æµ‹åˆ†æ”¯ (L198)
     pred_states_base, pred_exist_logits, residual_xy = decoder(
         predicted_latent,
         return_residual_xy=True  # â† è·å–residual
     )

  6. ğŸ”¥ ç‰©ç†å…ˆéªŒ + æ®‹å·® (L200-207)
     # è®¡ç®—è¿åŠ¨å­¦å…ˆéªŒ (åœ¨åŸå§‹ç©ºé—´è®¡ç®—ï¼Œç„¶åé‡æ–°æ ‡å‡†åŒ–)
     prior_xy = _kinematic_prior_xy(states)  # [B,T,K,2]

     # _kinematic_prior_xyå†…éƒ¨æµç¨‹ (L150-171):
     #   1. Denormalizeåˆ°åŸå§‹ç©ºé—´
     #      x = denorm(states[..., idx_x=0])
     #      y = denorm(states[..., idx_y=1])
     #      vx = denorm(states[..., idx_vx=2])
     #      vy = denorm(states[..., idx_vy=3])
     #      ax = denorm(states[..., idx_ax=4])
     #      ay = denorm(states[..., idx_ay=5])
     #
     #   2. åº”ç”¨è¿åŠ¨å­¦æ–¹ç¨‹ (ä½¿ç”¨åŠ é€Ÿåº¦)
     #      x_next = x + vx*dt + 0.5*ax*dt^2
     #      y_next = y + vy*dt + 0.5*ay*dt^2
     #      # dt = 1/30 â‰ˆ 0.0333 ç§’
     #
     #   3. Renormalizeå›æ ‡å‡†åŒ–ç©ºé—´
     #      x_next_norm = renorm(x_next)
     #      y_next_norm = renorm(y_next)
     #      return [x_next_norm, y_next_norm]

     # åº”ç”¨æ®‹å·®ä¿®æ­£ (maskæ‰padding agents)
     residual_xy = residual_xy * masks.unsqueeze(-1)
     pred_states[..., idx_x] = prior_xy[..., 0] + residual_xy[..., 0]
     pred_states[..., idx_y] = prior_xy[..., 1] + residual_xy[..., 1]

     # å…¶ä»–ç‰¹å¾ (vx,vy,ax,ay,angleç­‰) ç›´æ¥ä½¿ç”¨decoderè¾“å‡º

  7. è¿”å› (L209-215)
     return {
         "latent": latent,                          # [B,T,D]
         "reconstructed_states": recon_states,      # [B,T,K,F]
         "predicted_states": pred_states,           # [B,T,K,F] with prior+residual
         "existence_logits": exist_logits,          # [B,T,K]
         "predicted_existence_logits": pred_exist_logits,  # [B,T,K]
     }
```

**æ¶æ„äº®ç‚¹**:
1. âœ… **Transformer-onlyåŠ¨åŠ›å­¦**: ç§»é™¤RNNï¼Œå…¨é¢ä½¿ç”¨Transformerå»ºæ¨¡æ—¶åº
2. âœ… **Causal Masking**: ç¡®ä¿é¢„æµ‹æ—¶åªèƒ½çœ‹åˆ°è¿‡å»ä¿¡æ¯
3. âœ… **ç‰©ç†å…ˆéªŒ + å­¦ä¹ æ®‹å·®**: ç»“åˆè¿åŠ¨å­¦æ–¹ç¨‹å’Œç¥ç»ç½‘ç»œä¿®æ­£
4. âœ… **ä¸‰ç§embeddings**: Lane, Class, Siteä¸‰ç§ç¦»æ•£ç‰¹å¾embedding
5. âœ… **Normalization-aware**: ç‰©ç†å…ˆéªŒåœ¨åŸå§‹ç©ºé—´è®¡ç®—ï¼Œä¿è¯æ­£ç¡®æ€§

### æ­¥éª¤4: Lossè®¡ç®—è¯¦è§£

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**: `src/training/losses.py`

**Lossç»„æˆ** (WorldModelLoss L67-109):
```python
total_loss = recon_weight * recon_loss +        # é‡å»ºloss
             pred_weight * pred_loss +           # é¢„æµ‹loss
             exist_weight * (exist_loss +        # å­˜åœ¨æ€§loss (é‡å»º)
                            pred_exist_loss)     # å­˜åœ¨æ€§loss (é¢„æµ‹)
```

**å…³é”®å®ç°**:

```python
class WorldModelLoss(nn.Module):
    def __init__(
        self,
        recon_weight: float = 1.0,
        pred_weight: float = 1.0,
        exist_weight: float = 0.1,
        huber_beta: float = 1.0,  # Huber losså¹³æ»‘å‚æ•°
        continuous_indices: Optional[List[int]] = None,  # â† å…³é”®
        use_pred_existence_loss: bool = True,
    ):
        ...

    def _masked_huber_loss(self, pred, target, mask):
        """
        L39-57: ä»…å¯¹continuous_indicesè®¡ç®—Huber loss
        """
        if self.continuous_indices is not None:
            pred = pred[..., self.continuous_indices]    # â† è¿‡æ»¤åˆ°è¿ç»­ç‰¹å¾
            target = target[..., self.continuous_indices]

        # Huber loss (beta=1.0)
        diff = pred - target
        abs_diff = diff.abs()
        loss = torch.where(
            abs_diff < beta,
            0.5 * (diff ** 2) / beta,  # å°è¯¯å·®: quadratic
            abs_diff - 0.5 * beta       # å¤§è¯¯å·®: linear (robust)
        )

        # åº”ç”¨mask
        loss = loss * mask.unsqueeze(-1)
        return loss.sum() / (mask.sum() * loss.shape[-1]).clamp(min=1.0)
```

**Lossè®¡ç®—æµç¨‹** (forward L67-109):

```python
# 1. é‡å»ºloss (L86): å¯¹é½å½“å‰å¸§
recon_loss = _masked_huber_loss(
    recon_states,  # decoder(latent)
    states,        # ground truth
    masks
)

# 2. é¢„æµ‹loss (L89): té¢„æµ‹t+1
#    âš ï¸ æ—¶é—´å¯¹é½å¾ˆå…³é”®
pred_loss = _masked_huber_loss(
    pred_states[:, :-1],  # é¢„æµ‹: t=0åˆ°t=T-2
    states[:, 1:],        # ç›®æ ‡: t=1åˆ°t=T-1
    masks[:, :-1]         # maskå¯¹é½
)

# 3. å­˜åœ¨æ€§loss (L91): é‡å»ºåˆ†æ”¯
exist_loss = _existence_loss(exist_logits, masks)
# BCEWithLogitsLoss: sigmoid(logits) vs ground truth masks

# 4. é¢„æµ‹å­˜åœ¨æ€§loss (L94-95): é¢„æµ‹åˆ†æ”¯
if use_pred_existence_loss:
    pred_exist_loss = _existence_loss(
        predicted_existence_logits[:, :-1],  # æ—¶é—´å¯¹é½
        masks[:, 1:]
    )
```

**ä¸ºä»€ä¹ˆåªå¯¹è¿ç»­ç‰¹å¾è®¡ç®—loss**:
```
ç¦»æ•£ç‰¹å¾ (7, 8, 11):
- class_id, lane_id, site_idæ˜¯ç±»åˆ«å˜é‡
- ä¸åº”è¯¥ç”¨Huber/MSEå›å½’
- æ¨¡å‹é€šè¿‡embeddingå­¦ä¹ è¿™äº›ç‰¹å¾
- å›å½’lossä¼šè¯¯å¯¼å­¦ä¹ æ–¹å‘ (æŠŠæ•´æ•°å½“è¿ç»­å€¼ä¼˜åŒ–)

è¿ç»­ç‰¹å¾ (0-6, 9-10):
- center_x, center_y, vx, vy, ax, ay, angle, has_preceding, has_following
- é€‚åˆå›å½’ä»»åŠ¡
- Huber loss robust to outliers (ç›¸æ¯”MSE)
```

**continuous_indicesä»å“ªé‡Œæ¥**:
```python
# train_world_model.py L154
continuous_indices = train_loader.dataset.continuous_indices
# ç”±dataset.pyä»metadata.jsonè¯»å–

# dataset.pyè‡ªåŠ¨è®¡ç®—:
discrete_features = {lane_idx=8, class_idx=7, site_idx=11}
continuous_indices = [i for i in range(12) if i not in discrete_features]
# â†’ [0, 1, 2, 3, 4, 5, 6, 9, 10]
```

### æ­¥éª¤5: è®­ç»ƒæµç¨‹è¯¦è§£

**ä»£ç æ–‡ä»¶**: `src/training/train_world_model.py`

**ä¸»è¦æµç¨‹**:

```python
def main():
    # 1. è§£æå‚æ•° (L30-56)
    args = parse_args()

    # 2. åˆ›å»ºTRAIN loaderå¹¶è®¡ç®—normalization stats (L96-106)
    train_loader = get_dataloader(
        args.train_data,
        batch_size=args.batch_size,
        shuffle=True,
        normalize=True,
        stats_path=None  # é¦–æ¬¡è¿è¡Œï¼Œè‡ªåŠ¨è®¡ç®—stats
    )

    # ä¿å­˜normalization stats (ç”¨äºVAL/TEST)
    stats_path = ckpt_dir / "normalization_stats.npz"
    if not stats_path.exists():
        train_loader.dataset.save_stats(str(stats_path))

    # 3. åˆ›å»ºVAL loader (å¤ç”¨TRAINçš„stats) (L108-116)
    val_loader = get_dataloader(
        args.val_data,
        batch_size=args.batch_size,
        shuffle=False,
        normalize=True,
        stats_path=str(stats_path)  # â† ä½¿ç”¨TRAINçš„stats
    )

    # 4. ä»metadataè¯»å–é…ç½® (L118-123)
    meta = train_loader.dataset.metadata
    dt = float(meta.get("dt", 1.0/30.0))  # 0.0333ç§’
    num_lanes = int(meta.get("num_lanes", 100))
    num_sites = int(meta.get("num_sites", 10))
    num_classes = int(meta.get("num_classes", 10))

    # 5. åˆ›å»ºWorldModel (L127-140)
    model = WorldModel(
        input_dim=args.input_dim,
        max_agents=args.max_agents,
        latent_dim=args.latent_dim,
        dynamics_layers=args.dynamics_layers,      # Transformerå±‚æ•°
        dynamics_heads=args.dynamics_heads,        # æ³¨æ„åŠ›å¤´æ•°
        dt=dt,
        max_dynamics_len=args.max_dynamics_len,    # 512
        max_dynamics_context=args.max_dynamics_context,  # 128
        num_lanes=num_lanes,
        num_sites=num_sites,
        num_classes=num_classes,
        use_acceleration=bool(meta.get("use_acceleration", True)),
    ).to(device)

    # 6. âœ… è®¾ç½®normalization statsåˆ°model (L142-147)
    #    âš ï¸ å…³é”®: kinematic prioréœ€è¦è¿™äº›statsæ¥denorm/renorm
    model.set_normalization_stats(
        train_loader.dataset.mean,  # [n_continuous]
        train_loader.dataset.std,   # [n_continuous]
        train_loader.dataset.continuous_indices,  # [0,1,2,3,4,5,6,9,10]
    )

    # 7. åˆ›å»ºLosså‡½æ•° (L149-156)
    loss_fn = WorldModelLoss(
        recon_weight=1.0,
        pred_weight=1.0,
        exist_weight=0.1,
        huber_beta=1.0,
        continuous_indices=train_loader.dataset.continuous_indices,
        use_pred_existence_loss=True,
    )

    # 8. åˆ›å»ºOptimizer (L158)
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )

    # 9. è®­ç»ƒå¾ªç¯ (L162-199)
    for epoch in range(args.epochs):
        model.train()
        for batch in train_loader:
            states = batch["states"].to(device)  # [B,T,K,F]
            masks = batch["masks"].to(device)    # [B,T,K]

            optimizer.zero_grad(set_to_none=True)

            # Forward
            preds = model(states, masks)

            # Compute loss
            losses = loss_fn(preds, {"states": states, "masks": masks})
            loss = losses["total_loss"]

            # Backward
            loss.backward()
            if args.grad_clip > 0:
                clip_grad_norm_(model.parameters(), args.grad_clip)
            optimizer.step()

        # Validation
        val_metrics = evaluate(model, val_loader, loss_fn, device)

        # æ‰“å° (L190-192)
        print(f"[Epoch {epoch+1}] "
              f"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  "
              f"recon={val_metrics['recon_loss']:.4f} "
              f"pred={val_metrics['pred_loss']:.4f} "
              f"exist={val_metrics['exist_loss']:.4f}")

        # ä¿å­˜checkpoint (L194, L196-198)
        save_checkpoint(ckpt_dir / "checkpoint_last.pt", ...)
        if val_loss < best_val:
            save_checkpoint(ckpt_dir / "checkpoint_best.pt", ...)
```

**Checkpointä¿å­˜å†…å®¹** (save_checkpoint L59-68):
```python
{
    "epoch": epoch,
    "model_state_dict": model.state_dict(),
    "optimizer_state_dict": optimizer.state_dict(),
}
```

**Normalization statsä¿å­˜** (dataset.py):
```python
# checkpoints/world_model/normalization_stats.npz:
{
    "mean": [n_continuous],  # ä»…è¿ç»­ç‰¹å¾çš„mean
    "std": [n_continuous],   # ä»…è¿ç»­ç‰¹å¾çš„std
    "continuous_indices": [0,1,2,3,4,5,6,9,10],
}
```

### æ­¥éª¤6: ç›‘æ§è®­ç»ƒ

**å®æ—¶æŸ¥çœ‹è®­ç»ƒè¾“å‡º**:
```bash
# è„šæœ¬ç›´æ¥æ‰“å°åˆ°stdout
python src/training/train_world_model.py ... | tee train.log
```

**æœŸæœ›è¾“å‡º**:
```
[Epoch 1] train_loss=12.3456  val_loss=13.4567  recon=10.234 pred=2.345 exist=0.123 pred_exist=0.098
[Epoch 2] train_loss=10.1234  val_loss=11.2345  recon=8.456 pred=1.987 exist=0.112 pred_exist=0.089
...
[Epoch 25] train_loss=3.4567  val_loss=4.1234  recon=2.345 pred=0.987 exist=0.098 pred_exist=0.087
```

**å¥åº·æŒ‡æ ‡**:
- âœ… train_losså’Œval_lossé€epochä¸‹é™
- âœ… recon_lossé€šå¸¸ç•¥å¤§äºpred_loss (é‡å»ºæ›´éš¾)
- âœ… exist_losså’Œpred_exist_lossæ”¶æ•›åˆ°0.05-0.15
- âœ… val_lossç•¥é«˜äºtrain_loss,ä½†gapä¸åº”è¿‡å¤§ (é¿å…è¿‡æ‹Ÿåˆ)
- âœ… æ— NaNæˆ–Inf (è‹¥å‡ºç°,é™ä½lræˆ–æ£€æŸ¥æ•°æ®)

**Checkpointæ–‡ä»¶**:
```
checkpoints/world_model/
â”œâ”€â”€ checkpoint_last.pt          # æœ€æ–°epoch
â”œâ”€â”€ checkpoint_best.pt          # æœ€ä½³val_loss
â””â”€â”€ normalization_stats.npz     # æ ‡å‡†åŒ–ç»Ÿè®¡é‡
```

---

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°

### æ­¥éª¤1: Rolloutè¯„ä¼°

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**:
- ğŸ“„ **è¯„ä¼°è„šæœ¬**: `src/evaluation/rollout_eval.py`
- ğŸ“„ **æŒ‡æ ‡è®¡ç®—**: `src/evaluation/prediction_metrics.py`
- ğŸ“„ **å·¥å…·å‡½æ•°**: `src/utils/common.py`

**å‘½ä»¤**:
```bash
python src/evaluation/rollout_eval.py \
    --checkpoint checkpoints/best_model.pt \
    --test_data data/processed/test_episodes.npz \
    --context_length 65 \
    --rollout_horizon 15 \
    --output_dir results/
```

**è¯„ä¼°æµç¨‹**:

```
src/evaluation/rollout_eval.py
  â†“
1. åŠ è½½æ¨¡å‹ (L320-395)
   â”œâ”€ è¯»å–checkpoint
   â”œâ”€ æ¨æ–­æ¨¡å‹é…ç½® (latent_dim, dynamics_type, hidden_dim)
   â”‚   â””â”€ é€šè¿‡æƒé‡çŸ©é˜µå½¢çŠ¶æ¨æ–­ (ä¿®å¤åçš„é€»è¾‘)
   â””â”€ åˆ›å»ºWorldModelå¹¶åŠ è½½æƒé‡
  â†“
2. åŠ è½½æµ‹è¯•æ•°æ® (L369-375)
   â””â”€ ä½¿ç”¨src/data/dataset.pyçš„TrajectoryDataset
  â†“
3. Rolloutè¯„ä¼° (evaluate_rollout L23-97)
   for batch in test_loader:
       # åˆ†å‰²contextå’Œtarget
       context_states = states[:, :C=65]
       target_states = states[:, C:C+H=15]

       # Rollouté¢„æµ‹ (è°ƒç”¨world_model.py:rollout)
       rollout_output = model.rollout(
           initial_states=context_states,
           initial_masks=context_masks,
           n_steps=H=15,
           teacher_forcing=False  # Open-loop
       )

       # è®¡ç®—æŒ‡æ ‡ (è°ƒç”¨prediction_metrics.py)
       metrics = compute_all_metrics(
           predicted=rollout_output['predicted_states'],
           ground_truth=target_states,
           masks=target_masks,
           convert_to_meters=True  # è½¬æ¢ä¸ºç±³
       )
  â†“
4. ä¿å­˜ç»“æœ (L412-431)
   â””â”€ results/rollout_metrics.json
```

**World Model Rolloutè¯¦è§£**:

**æ–°rolloutå®ç°** (src/models/world_model.py L217-296):

```python
@torch.no_grad()
def rollout(
    initial_states,      # [B, T0=65, K, F]
    initial_masks,       # [B, T0, K]
    n_steps=15,          # é¢„æµ‹æ­¥æ•°
    threshold=0.5,       # å­˜åœ¨æ€§é˜ˆå€¼
    teacher_forcing=False,
    ground_truth_states=None,
):
    """
    ğŸ”¥ æ–°ç‰ˆrollout: ä½¿ç”¨Transformer dynamics.step() + Kinematic Prior

    å…³é”®æ”¹è¿›:
    1. ä½¿ç”¨dynamics.step()è¿›è¡Œå•æ­¥é¢„æµ‹ (æ”¯æŒtruncated context)
    2. åº”ç”¨kinematic prior + residualä¿®æ­£(x,y)
    3. ç´¯ç§¯latentå†å² (ç”¨äºTransformerçš„attention)
    """
    B, T0, K, F = initial_states.shape

    # 1. ç¼–ç context (L243)
    latent_ctx = encoder(initial_states, initial_masks)  # [B,T0,D]
    time_padding = (initial_masks.sum(dim=-1) == 0)  # [B,T0]

    # 2. é€šè¿‡dynamicsè·å–contextçš„é¢„æµ‹latent (L246-247)
    pred_latent_ctx, _ = dynamics(latent_ctx, time_padding_mask=time_padding)
    current_latent = pred_latent_ctx[:, -1:, :]  # [B,1,D] æœ€åä¸€æ­¥çš„é¢„æµ‹

    # 3. åˆå§‹åŒ–å†å²å’ŒçŠ¶æ€ (L249-250)
    latent_hist = latent_ctx          # å†å²latentåºåˆ— [B,T0,D]
    prev_state = initial_states[:, -1:, :, :]  # [B,1,K,F] æœ€åä¸€å¸§

    out_states = []
    out_masks = []

    # 4. Autoregressive rolloutå¾ªç¯ (L255-292)
    for step in range(n_steps):  # 15æ­¥
        # a. è§£ç å½“å‰latent (L257-259)
        base_states, exist_logits, residual_xy = decoder(
            current_latent,
            return_residual_xy=True  # è·å–(x,y)æ®‹å·®
        )
        pred_state = base_states.clone()  # [B,1,K,F]

        # b. ğŸ”¥ åº”ç”¨kinematic prior (L262-266)
        prior_xy = _kinematic_prior_xy(prev_state)  # [B,1,K,2]
        # prior_xyåŸºäºprev_stateçš„(vx,vy,ax,ay)è®¡ç®—ç‰©ç†é¢„æµ‹

        if residual_xy is not None:
            pred_state[..., idx_x] = prior_xy[..., 0] + residual_xy[..., 0]
            pred_state[..., idx_y] = prior_xy[..., 1] + residual_xy[..., 1]

        # c. å­˜åœ¨æ€§mask (L269-270)
        exist_prob = torch.sigmoid(exist_logits)  # logits â†’ prob
        pred_mask = (exist_prob > threshold).float()  # [B,1,K]

        out_states.append(pred_state)
        out_masks.append(pred_mask)

        # d. å†³å®šä¸‹ä¸€æ­¥çš„"prev_state" (L275-284)
        if teacher_forcing and ground_truth_states is not None:
            # ä½¿ç”¨ground truth (ç”¨äºè®­ç»ƒé˜¶æ®µçš„scheduled sampling)
            gt_state = ground_truth_states[:, T0+step:T0+step+1, :, :]
            prev_state = gt_state
            gt_mask = (gt_state.abs().sum(dim=-1) > 0).float()
            current_latent = encoder(gt_state, gt_mask)
        else:
            # ä½¿ç”¨é¢„æµ‹ç»“æœ (open-loop)
            prev_state = pred_state * pred_mask.unsqueeze(-1)

        # e. ç´¯ç§¯latentå†å²ï¼Œé¢„æµ‹ä¸‹ä¸€æ­¥ (L287-292)
        latent_hist = torch.cat([latent_hist, current_latent], dim=1)
        # latent_hist: [B, T0+step+1, D]

        next_latent = dynamics.step(
            latent_hist,
            max_context=self.max_dynamics_context  # 128 (truncateé•¿å†å²)
        ).view(B, 1, -1)  # [B,1,D]

        current_latent = next_latent

    # 5. æ‹¼æ¥è¾“å‡º (L294-296)
    predicted_states = torch.cat(out_states, dim=1)  # [B,n_steps=15,K,F]
    predicted_masks = torch.cat(out_masks, dim=1)    # [B,n_steps,K]

    return predicted_states, predicted_masks
```

**å…³é”®æ¶æ„ç‰¹ç‚¹**:

1. **Transformer dynamics.step() (L288-291)**:
   ```python
   # dynamics.py: step method (L127-154)
   def step(latent_history, time_padding_mask=None, max_context=None):
       """
       å•æ­¥é¢„æµ‹ï¼Œæ”¯æŒtruncated context
       """
       if max_context and latent_history.size(1) > max_context:
           # åªä¿ç•™æœ€è¿‘max_contextæ­¥ (æ•ˆç‡ä¼˜åŒ–)
           latent_history = latent_history[:, -max_context:, :]

       pred, _ = forward(latent_history, time_padding_mask)
       return pred[:, -1, :]  # è¿”å›æœ€åä¸€ä¸ªtokençš„é¢„æµ‹
   ```

2. **Kinematic Prioråº”ç”¨ (L262-266)**:
   - ç‰©ç†å…ˆéªŒåœ¨**åŸå§‹ç©ºé—´**è®¡ç®— (denormalize â†’ physics â†’ renormalize)
   - æ®‹å·®ä»decoderè¾“å‡º,åˆå§‹åŒ–ä¸º0
   - åªä¿®æ­£(x,y),å…¶ä»–ç‰¹å¾ç›´æ¥ä½¿ç”¨decoderè¾“å‡º

3. **ç´¯ç§¯Latentå†å² (L287)**:
   - Transformeréœ€è¦å®Œæ•´å†å²æ¥åšattention
   - ä½¿ç”¨truncated context (128æ­¥) é¿å…è¶…é•¿åºåˆ—

4. **Open-loop vs Teacher Forcing (L275-284)**:
   - Open-loop: ä½¿ç”¨è‡ªå·±çš„é¢„æµ‹ `prev_state = pred_state`
   - Teacher forcing: ä½¿ç”¨ground truth (è®­ç»ƒæ—¶å¯ç”¨)

**ä¸æ—§ç‰ˆæœ¬çš„åŒºåˆ«**:
| ç‰¹æ€§ | æ—§ç‰ˆ (GRU/LSTM) | æ–°ç‰ˆ (Transformer) |
|------|----------------|-------------------|
| Dynamics | RNN hidden state | Latentå†å²åºåˆ— |
| å•æ­¥é¢„æµ‹ | `dynamics(current_latent, hidden)` | `dynamics.step(latent_hist, max_context=128)` |
| ç‰©ç†å…ˆéªŒ | æ—  | Kinematic prior + residual |
| Context | Hidden state | Truncated latent history |
| (x,y)é¢„æµ‹ | ç›´æ¥è¾“å‡º | Prior + Residual |

### æ­¥éª¤2: æŒ‡æ ‡è®¡ç®—

**ä»£ç æ–‡ä»¶**: `src/evaluation/prediction_metrics.py`

**æŒ‡æ ‡è¯¦è§£**:

```python
# prediction_metrics.py: compute_all_metrics (L257-319)

def compute_all_metrics(predicted, ground_truth, masks, convert_to_meters=True):
    """
    è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡

    æŒ‡æ ‡åˆ—è¡¨:
    1. ADE (Average Displacement Error)  - L18-50
    2. FDE (Final Displacement Error)    - L53-86
    3. Velocity Error                     - L89-121
    4. Heading Error                      - L124-160
    5. Collision Rate                     - L163-217
    """

    # åæ ‡è½¬æ¢ (L282-301)
    if convert_to_meters:
        # ä½¿ç”¨src/utils/common.py:convert_pixels_to_meters
        pixel_to_meter = get_pixel_to_meter_conversion()  # â‰ˆ 0.077

        predicted = convert_pixels_to_meters(
            predicted,
            pixel_to_meter,
            position_indices=(0, 1),
            velocity_indices=(2, 3),
            acceleration_indices=(4, 5)
        )
        ground_truth = convert_pixels_to_meters(ground_truth, ...)

    # è®¡ç®—å„é¡¹æŒ‡æ ‡ (L303-318)
    metrics = {
        'ade': compute_ade(predicted, ground_truth, masks),
        'fde': compute_fde(predicted, ground_truth, masks),
        'velocity_error': compute_velocity_error(...),
        'heading_error': compute_heading_error(...),
        'collision_rate': compute_collision_rate(...)
    }

    return metrics
```

**ADE/FDEè®¡ç®—**:
```python
# ADE: å¹³å‡ä½ç§»è¯¯å·® (L18-50)
def compute_ade(predicted, ground_truth, masks):
    # æå–ä½ç½® (x, y)
    pred_pos = predicted[..., :2]  # [B, T, K, 2]
    gt_pos = ground_truth[..., :2]

    # L2è·ç¦»
    displacement = torch.norm(pred_pos - gt_pos, dim=-1)  # [B, T, K]

    # åº”ç”¨maskå¹¶æ±‚å¹³å‡
    masked_displacement = displacement * masks
    ade = masked_displacement.sum() / masks.sum().clamp(min=1)

    return ade.item()  # å•ä½: ç±³

# FDE: æœ€ç»ˆä½ç§»è¯¯å·® (L53-86)
def compute_fde(predicted, ground_truth, masks):
    # ä»…æœ€åä¸€å¸§
    pred_final = predicted[:, -1, :, :2]  # [B, K, 2]
    gt_final = ground_truth[:, -1, :, :2]
    mask_final = masks[:, -1, :]

    # L2è·ç¦»
    displacement = torch.norm(pred_final - gt_final, dim=-1)

    # å¹³å‡
    fde = (displacement * mask_final).sum() / mask_final.sum().clamp(min=1)

    return fde.item()  # å•ä½: ç±³
```

**æœŸæœ›ç»“æœ** (è‰¯å¥½æ¨¡å‹):
```json
{
  "ade": 0.10,          // 10å˜ç±³å¹³å‡è¯¯å·®
  "fde": 0.12,          // 12å˜ç±³æœ€ç»ˆè¯¯å·®
  "velocity_error": 0.08,   // 8cm/sé€Ÿåº¦è¯¯å·®
  "heading_error": 1.5,     // 1.5åº¦æœå‘è¯¯å·®
  "collision_rate": 5.2     // 5.2% (å–å†³äºsafety_margin)
}
```

---

## ğŸ¨ å¯è§†åŒ–

### æ­¥éª¤1: è½¨è¿¹å¯è§†åŒ–

**ä½¿ç”¨çš„ä»£ç æ–‡ä»¶**:
- ğŸ“„ **å¯è§†åŒ–è„šæœ¬**: `src/evaluation/visualize_predictions.py`
- ğŸ“„ **èˆªæ‹å›¾**: `src/evaluation/sites/SiteA.jpg` ~ `SiteI.jpg`

**å‘½ä»¤**:
```bash
python src/evaluation/visualize_predictions.py \
    --checkpoint checkpoints/best_model.pt \
    --test_data data/processed/test_episodes.npz \
    --site_images_dir src/evaluation/sites \
    --context_length 65 \
    --rollout_horizon 15 \
    --output_dir results/visualizations \
    --num_samples 5 \
    --max_agents 10
```

**å¯è§†åŒ–æµç¨‹**:

```
src/evaluation/visualize_predictions.py
  â†“
1. åŠ è½½ç«™ç‚¹èˆªæ‹å›¾ (L150-157)
   for site in A-I:
       load SiteX.jpg
  â†“
2. æ”¶é›†æµ‹è¯•æ ·æœ¬ (L161-222)
   for batch in test_loader:
       # åˆ†å‰²contextå’Œtarget
       context = states[:, :C=65]      # è“è‰²è½¨è¿¹
       target = states[:, C:C+H=15]    # ç»¿è‰²è½¨è¿¹(çœŸå®)

       # å½’ä¸€åŒ–ç»™æ¨¡å‹
       context_norm = normalize_states(context, mean, std, continuous_indices)

       # Rollouté¢„æµ‹
       predictions_norm = model.rollout(context_norm, n_steps=15)

       # åå½’ä¸€åŒ–å›åƒç´ åæ ‡
       predictions = denormalize_states(
           predictions_norm, mean, std, continuous_indices
       )  # çº¢è‰²è½¨è¿¹(é¢„æµ‹)

       # æ”¶é›†æ ·æœ¬ (æ¯ä¸ªsite 5ä¸ªæ ·æœ¬)
       samples_by_site[site_id].append({
           'context': context,
           'ground_truth': target,
           'predicted': predictions
       })
  â†“
3. ç»˜åˆ¶è½¨è¿¹ (L224-306)
   for site in A-I:
       for sample in samples:
           # åœ¨èˆªæ‹å›¾ä¸Šç»˜åˆ¶
           img = load_site_image(site)

           # ç»˜åˆ¶æ¯ä¸ªagentçš„è½¨è¿¹ (æœ€å¤š10ä¸ª)
           for agent_idx in valid_agents[:10]:
               # è“è‰²: contextè½¨è¿¹
               draw_trajectory(img, context[:, agent_idx, :2], color=(0,0,255))

               # ç»¿è‰²: ground truthè½¨è¿¹
               draw_trajectory(img, gt[:, agent_idx, :2], color=(0,255,0))

               # çº¢è‰²: é¢„æµ‹è½¨è¿¹
               draw_trajectory(img, pred[:, agent_idx, :2], color=(255,0,0))

           # æ·»åŠ å›¾ä¾‹
           add_legend(img)

           # ä¿å­˜
           save(f'site_{site}_sample_{idx}.jpg')
  â†“
è¾“å‡º: results/visualizations/
    â”œâ”€â”€ site_A_sample_1.jpg
    â”œâ”€â”€ site_A_sample_2.jpg
    ...
    â””â”€â”€ site_I_sample_5.jpg
```

**ç»˜åˆ¶å‡½æ•°è¯¦è§£**:
```python
# visualize_predictions.py: draw_trajectory_on_image (L58-106)

def draw_trajectory_on_image(img, trajectory, color, thickness=2):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶å•æ¡è½¨è¿¹

    å‚æ•°:
        img: èˆªæ‹å›¾ [H, W, 3]
        trajectory: [T, 2] è½¨è¿¹åæ ‡ (åƒç´ )
        color: (R, G, B) é¢œè‰²
    """
    import cv2

    # è¿‡æ»¤æ— æ•ˆç‚¹
    valid_mask = (trajectory[:, 0] > 0) & (trajectory[:, 1] > 0)
    trajectory = trajectory[valid_mask]

    # ç»˜åˆ¶è¿çº¿
    for i in range(len(trajectory) - 1):
        pt1 = (int(trajectory[i, 0]), int(trajectory[i, 1]))
        pt2 = (int(trajectory[i+1, 0]), int(trajectory[i+1, 1]))
        cv2.line(img, pt1, pt2, color, thickness)

    # ç»˜åˆ¶ç‚¹
    for pt in trajectory:
        cv2.circle(img, (int(pt[0]), int(pt[1])), 3, color, -1)

    # èµ·ç‚¹: å¤§åœ†åœˆ
    cv2.circle(img, (int(trajectory[0, 0]), int(trajectory[0, 1])), 6, color, 2)

    # ç»ˆç‚¹: æ–¹å—
    end_pt = (int(trajectory[-1, 0]), int(trajectory[-1, 1]))
    cv2.rectangle(img, (end_pt[0]-4, end_pt[1]-4), (end_pt[0]+4, end_pt[1]+4), color, -1)

    return img
```

**å¯è§†åŒ–ç»“æœç¤ºä¾‹**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ èˆªæ‹å›¾: Site A                      â”‚
â”‚                                     â”‚
â”‚  è“è‰²çº¿æ¡ â”â”â”â”â”â”â”â”â”â”â”               â”‚
â”‚                     â†“ Context (65å¸§)â”‚
â”‚                     â—               â”‚
â”‚  ç»¿è‰²çº¿æ¡ â”â”â”â”â”â”â”â”â”â” Ground Truth   â”‚
â”‚                     â†“ (15å¸§)        â”‚
â”‚                     â–                â”‚
â”‚  çº¢è‰²çº¿æ¡ â”â”â”â”â”â”â”â”â”â” Prediction     â”‚
â”‚                     â†“ (15å¸§)        â”‚
â”‚                     â–                â”‚
â”‚                                     â”‚
â”‚ å›¾ä¾‹: Blue=Context, Green=GT,       â”‚
â”‚       Red=Prediction                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ­¥éª¤2: Attentionæƒé‡å¯è§†åŒ–

**ä»£ç æ–‡ä»¶**: `src/evaluation/attention_visualization.py`

```bash
python src/evaluation/attention_visualization.py \
    --checkpoint checkpoints/best_model.pt \
    --test_data data/processed/test_episodes.npz \
    --output_dir results/attention_maps
```

**å¯è§†åŒ–å†…å®¹**:
- Encoderçš„Transformer attentionæƒé‡
- è·¨agentçš„attention pattern
- åˆ†æå“ªäº›agentä¹‹é—´äº¤äº’æœ€å¼º

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
traffic_wm/
â”œâ”€â”€ ğŸ“„ README.md                        # æœ¬æ–‡ä»¶ - ç”¨æˆ·æŒ‡å—
â”œâ”€â”€ ğŸ“„ CLAUDE.md                        # å¼€å‘è€…æŒ‡å— (è¯¦ç»†æŠ€æœ¯è¯´æ˜)
â”œâ”€â”€ ğŸ“„ WORLD_MODEL_COMPARISON.md        # ä¸DreamerV3çš„æ¶æ„å¯¹æ¯”
â”œâ”€â”€ ğŸ“„ requirements.txt                 # Pythonä¾èµ–
â”‚
â”œâ”€â”€ ğŸ“„ preprocess_multisite.py          # â­ é¢„å¤„ç†ä¸»è„šæœ¬
â”œâ”€â”€ ğŸ“„ validate_preprocessing.py        # â­ éªŒè¯è„šæœ¬
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                            # åŸå§‹CSVæ•°æ® (ç”¨æˆ·æä¾›)
â”‚   â”‚   â”œâ”€â”€ A/drone_1.csv, drone_2.csv, ...
â”‚   â”‚   â”œâ”€â”€ B/drone_1.csv, ...
â”‚   â”‚   â””â”€â”€ I/...
â”‚   â””â”€â”€ processed/                      # é¢„å¤„ç†è¾“å‡º
â”‚       â”œâ”€â”€ train_episodes.npz          # [N, 80, 50, 12]
â”‚       â”œâ”€â”€ val_episodes.npz
â”‚       â”œâ”€â”€ test_episodes.npz
â”‚       â”œâ”€â”€ metadata.json               # å…ƒæ•°æ®é…ç½®
â”‚       â””â”€â”€ split_config.json           # æ•°æ®åˆ’åˆ†è®°å½•
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ preprocess.py            # é¢„å¤„ç†æ ¸å¿ƒé€»è¾‘
â”‚   â”‚   â”‚   â”œâ”€ build_global_timeline()
â”‚   â”‚   â”‚   â”œâ”€ detect_gaps_and_split_segments()
â”‚   â”‚   â”‚   â”œâ”€ extract_fixed_stride_episodes()
â”‚   â”‚   â”‚   â””â”€ extract_extended_features()
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ split_strategy.py        # æ•°æ®åˆ’åˆ†ç­–ç•¥
â”‚   â”‚   â”‚   â””â”€ chronological_split_episodes()
â”‚   â”‚   â””â”€â”€ ğŸ“„ dataset.py               # PyTorch Dataset/DataLoader
â”‚   â”‚       â””â”€ TrajectoryDataset
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ encoder.py               # â­ MultiAgentEncoder
â”‚   â”‚   â”‚   â”œâ”€ Feature Embedding
â”‚   â”‚   â”‚   â”œâ”€ Site/Lane Embeddings
â”‚   â”‚   â”‚   â”œâ”€ Transformer Attention
â”‚   â”‚   â”‚   â””â”€ Masked Mean Pooling
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ decoder.py               # â­ StateDecoder
â”‚   â”‚   â”‚   â”œâ”€ MLP Layers
â”‚   â”‚   â”‚   â”œâ”€ State Head ([K, F])
â”‚   â”‚   â”‚   â””â”€ Existence Head ([K])
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dynamics.py              # â­ LatentDynamics
â”‚   â”‚   â”‚   â”œâ”€ GRUDynamics
â”‚   â”‚   â”‚   â”œâ”€ LSTMDynamics
â”‚   â”‚   â”‚   â””â”€ TransformerDynamics
â”‚   â”‚   â””â”€â”€ ğŸ“„ world_model.py           # â­ WorldModel
â”‚   â”‚       â”œâ”€ forward()
â”‚   â”‚       â””â”€ rollout()  â† ä¿®å¤åçš„å®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ training/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ train_world_model.py     # â­ è®­ç»ƒä¸»è„šæœ¬
â”‚   â”‚   â”‚   â”œâ”€ Trainer class
â”‚   â”‚   â”‚   â”œâ”€ train_epoch()
â”‚   â”‚   â”‚   â”œâ”€ validate()
â”‚   â”‚   â”‚   â””â”€ save_checkpoint()
â”‚   â”‚   â””â”€â”€ ğŸ“„ losses.py                # â­ Losså‡½æ•°
â”‚   â”‚       â”œâ”€ WorldModelLoss
â”‚   â”‚       â”‚   â”œâ”€ Reconstruction Loss (ä»…è¿ç»­ç‰¹å¾)
â”‚   â”‚       â”‚   â”œâ”€ Prediction Loss (ä»…è¿ç»­ç‰¹å¾)
â”‚   â”‚       â”‚   â””â”€ Existence Loss
â”‚   â”‚       â”œâ”€ RolloutLoss
â”‚   â”‚       â””â”€ ContrastiveLoss
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ evaluation/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ rollout_eval.py          # â­ Rolloutè¯„ä¼°
â”‚   â”‚   â”‚   â”œâ”€ evaluate_rollout()
â”‚   â”‚   â”‚   â”œâ”€ evaluate_multihorizon()
â”‚   â”‚   â”‚   â””â”€ evaluate_with_teacher_forcing()
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ prediction_metrics.py    # â­ è¯„ä¼°æŒ‡æ ‡
â”‚   â”‚   â”‚   â”œâ”€ compute_ade()
â”‚   â”‚   â”‚   â”œâ”€ compute_fde()
â”‚   â”‚   â”‚   â”œâ”€ compute_velocity_error()
â”‚   â”‚   â”‚   â”œâ”€ compute_heading_error()
â”‚   â”‚   â”‚   â”œâ”€ compute_collision_rate()
â”‚   â”‚   â”‚   â””â”€ compute_all_metrics()
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ visualize_predictions.py # â­ è½¨è¿¹å¯è§†åŒ–
â”‚   â”‚   â”‚   â”œâ”€ visualize_batch_predictions()
â”‚   â”‚   â”‚   â”œâ”€ draw_trajectory_on_image()
â”‚   â”‚   â”‚   â””â”€ denormalize_states()
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ visualization.py         # å…¶ä»–å¯è§†åŒ–
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ attention_visualization.py # Attentionæƒé‡å¯è§†åŒ–
â”‚   â”‚   â””â”€â”€ ğŸ“‚ sites/                   # ç«™ç‚¹èˆªæ‹å›¾
â”‚   â”‚       â”œâ”€â”€ SiteA.jpg
â”‚   â”‚       â”œâ”€â”€ SiteB.jpg
â”‚   â”‚       â””â”€â”€ ... SiteI.jpg
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ logger.py                # æ—¥å¿—å·¥å…·
â”‚       â”œâ”€â”€ ğŸ“„ common.py                # é€šç”¨å·¥å…·å‡½æ•°
â”‚       â”‚   â”œâ”€ set_seed()
â”‚       â”‚   â”œâ”€ count_parameters()
â”‚       â”‚   â”œâ”€ get_pixel_to_meter_conversion()
â”‚       â”‚   â””â”€ convert_pixels_to_meters()
â”‚       â””â”€â”€ ğŸ“„ config.py                # é…ç½®ç®¡ç†
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                            # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ trainer.log
â”‚
â”œâ”€â”€ ğŸ“‚ checkpoints/                     # æ¨¡å‹checkpoints
â”‚   â”œâ”€â”€ best_model.pt                   # æœ€ä½³æ¨¡å‹
â”‚   â””â”€â”€ checkpoint_epoch_N.pt           # å®šæœŸä¿å­˜
â”‚
â”œâ”€â”€ ğŸ“‚ results/                         # è¯„ä¼°ç»“æœ
â”‚   â”œâ”€â”€ rollout_metrics.json            # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ visualizations/                 # å¯è§†åŒ–ç»“æœ
â”‚       â”œâ”€â”€ site_A_sample_1.jpg
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ“‚ dreamerv3/                       # DreamerV3å‚è€ƒå®ç°
    â”œâ”€â”€ nets.py                         # RSSM, MultiEncoder, MultiDecoder
    â””â”€â”€ agent.py                        # WorldModel
```

---

## ğŸ” ä»£ç æ–‡ä»¶è¯¦è§£

### æ ¸å¿ƒæ•°æ®æµ

```
æ•°æ®æµå‘:

  CSVæ–‡ä»¶ (data/raw/)
    â†“ preprocess_multisite.py
    â†“ src/data/preprocess.py
  NPZæ–‡ä»¶ (data/processed/)
    â†“ src/data/dataset.py: TrajectoryDataset
    â†“ torch.utils.data.DataLoader
  Batch [B, T, K, F]
    â†“ src/models/encoder.py: MultiAgentEncoder
  Latent [B, T, D]
    â†“ src/models/dynamics.py: LatentDynamics
  Predicted Latent [B, T, D]
    â†“ src/models/decoder.py: StateDecoder
  States [B, T, K, F] + Existence [B, T, K]
    â†“ src/training/losses.py: WorldModelLoss
  Loss (ä»…è¿ç»­ç‰¹å¾!)
    â†“ optimizer.step()
  Updated Model
```

### å…³é”®å‡½æ•°è°ƒç”¨é“¾

**è®­ç»ƒæ—¶**:
```python
src/training/train_world_model.py:main()
  â””â”€ Trainer.__init__()
      â”œâ”€ src/data/dataset.py:TrajectoryDataset(normalize=True)
      â”œâ”€ src/models/world_model.py:WorldModel()
      â”‚   â”œâ”€ src/models/encoder.py:MultiAgentEncoder()
      â”‚   â”œâ”€ src/models/dynamics.py:LatentDynamics()
      â”‚   â””â”€ src/models/decoder.py:StateDecoder()
      â””â”€ src/training/losses.py:WorldModelLoss()

  â””â”€ Trainer.train()
      â””â”€ for epoch in range(n_epochs):
          â”œâ”€ Trainer.train_epoch()
          â”‚   â””â”€ for batch in train_loader:
          â”‚       â”œâ”€ model.forward(states, masks)
          â”‚       â”œâ”€ loss_fn(predictions, targets)
          â”‚       â””â”€ optimizer.step()
          â”‚
          â”œâ”€ Trainer.validate()
          â””â”€ Trainer.save_checkpoint()
```

**è¯„ä¼°æ—¶**:
```python
src/evaluation/rollout_eval.py:main()
  â”œâ”€ åŠ è½½checkpoint
  â”œâ”€ åˆ›å»ºWorldModel
  â”œâ”€ åˆ›å»ºTrajectoryDataset(test)
  â”‚
  â””â”€ evaluate_rollout()
      â””â”€ for batch in test_loader:
          â”œâ”€ model.rollout(context, n_steps=15)
          â”‚   â”œâ”€ encoder(context) â†’ latent
          â”‚   â”œâ”€ dynamics(latent) â†’ predicted_latent_context
          â”‚   â””â”€ for step in range(15):
          â”‚       â”œâ”€ dynamics(current_latent) â†’ next_latent
          â”‚       â”œâ”€ decoder(next_latent) â†’ next_states
          â”‚       â””â”€ current_latent = next_latent
          â”‚
          â””â”€ src/evaluation/prediction_metrics.py:compute_all_metrics()
              â”œâ”€ compute_ade()
              â”œâ”€ compute_fde()
              â”œâ”€ compute_velocity_error()
              â””â”€ ...
```

**å¯è§†åŒ–æ—¶**:
```python
src/evaluation/visualize_predictions.py:main()
  â”œâ”€ åŠ è½½checkpoint
  â”œâ”€ åŠ è½½ç«™ç‚¹å›¾ç‰‡
  â”œâ”€ åˆ›å»ºTrajectoryDataset(test, normalize=False)
  â”‚
  â””â”€ visualize_batch_predictions()
      â””â”€ for batch in test_loader:
          â”œâ”€ åˆ†å‰²context/target
          â”œâ”€ normalize_states(context) â†’ context_norm
          â”œâ”€ model.rollout(context_norm) â†’ predictions_norm
          â”œâ”€ denormalize_states(predictions_norm) â†’ predictions
          â”‚
          â””â”€ for agent in agents:
              â”œâ”€ draw_trajectory(context, color=blue)
              â”œâ”€ draw_trajectory(target, color=green)
              â””â”€ draw_trajectory(predictions, color=red)
```

---

## âš ï¸ é‡è¦è¯´æ˜

### 1. ç¦»æ•£ç‰¹å¾å¤„ç†ï¼ˆå…³é”®ï¼ï¼‰

**ä¸ºä»€ä¹ˆé‡è¦**: è¿™æ˜¯æœ€å¸¸è§çš„é”™è¯¯æ¥æºï¼

**æ•°æ®åŠ è½½æ—¶** (`src/data/dataset.py:_normalize_data`):
```python
# âœ… æ­£ç¡®åšæ³•
continuous_feats = states[..., continuous_indices]  # [0,1,2,3,4,5,6,9,10]
continuous_feats = (continuous_feats - mean) / std

states[..., continuous_indices] = continuous_feats
# ç¦»æ•£ç‰¹å¾ [7, 8, 11] ä¿æŒä¸å˜!
```

**æ¨¡å‹ä¸­** (`src/models/encoder.py`):
```python
# âœ… ç¦»æ•£ç‰¹å¾é€šè¿‡Embeddingå­¦ä¹ 
site_id = states[..., 11].long()       # æå–site_id
lane_id = states[..., 8].long()        # æå–lane_id

site_embed = self.site_embedding(site_id)
lane_embed = self.lane_embedding(lane_id)
# ä¸å‚ä¸è¿ç»­ç‰¹å¾çš„æ ‡å‡†åŒ–!
```

**Lossè®¡ç®—æ—¶** (`src/training/losses.py`):
```python
# âœ… ä»…å¯¹è¿ç»­ç‰¹å¾è®¡ç®—å›å½’loss
continuous_indices = [0, 1, 2, 3, 4, 5, 6, 9, 10]

recon_loss = huber_loss(
    pred[..., continuous_indices],
    target[..., continuous_indices],
    mask
)
# ç¦»æ•£ç‰¹å¾ä¸å‚ä¸lossè®¡ç®—!
```

**é”™è¯¯ç¤ºä¾‹** âŒ:
```python
# âŒ é”™è¯¯: å¯¹æ‰€æœ‰ç‰¹å¾æ ‡å‡†åŒ–
states = (states - mean) / std  # lane_id=150å˜æˆäº†150.3!

# âŒ é”™è¯¯: å¯¹ç¦»æ•£ç‰¹å¾è®¡ç®—å›å½’loss
loss = mse(pred[:, :, :, :], target[:, :, :, :])  # åŒ…æ‹¬lane_id!

# âŒ é”™è¯¯: å¯¹lane_idåšå›å½’é¢„æµ‹
predicted_lane = 150.73  # åº”è¯¥æ˜¯æ•´æ•°!
```

### 2. è¾“å…¥ç»´åº¦åŒ¹é…

**æ£€æŸ¥æ–¹æ³•**:
```bash
# 1. æŸ¥çœ‹metadataä¸­çš„ç‰¹å¾æ•°
cat data/processed/metadata.json | grep n_features
# è¾“å‡º: "n_features": 12

# 2. è®­ç»ƒæ—¶å¿…é¡»åŒ¹é…
python src/training/train_world_model.py --input_dim 12 ...
```

**å¸¸è§é”™è¯¯**:
```bash
# âŒ é”™è¯¯: input_dimä¸åŒ¹é…
python src/training/train_world_model.py --input_dim 11 ...
# RuntimeError: Expected 11 features, got 12

# âœ… æ­£ç¡®
python src/training/train_world_model.py --input_dim 12 ...
```

### 3. Lane Tokenæ ¼å¼

**Lane mappingæ ¼å¼**: `"site:lane"`

**éªŒè¯**:
```bash
cat data/processed/metadata.json | grep -A 10 lane_mapping
```

**æœŸæœ›è¾“å‡º**:
```json
"lane_mapping": {
    "A:A1": 1,
    "A:A2": 2,
    "A:B1": 3,
    "B:crossroads1": 4,
    ...
}
```

### 4. Rolloutä¿®å¤ (2025-12-14)

**ä¿®å¤å‰** âŒ:
```python
# src/models/world_model.py:189 (æ—§ç‰ˆæœ¬)
current_latent = latent[:, -1:]  # ä½¿ç”¨encoderçš„è¾“å‡º
```

**ä¿®å¤å** âœ…:
```python
# src/models/world_model.py:191 (æ–°ç‰ˆæœ¬)
predicted_latent_context, hidden = self.dynamics(latent)
current_latent = predicted_latent_context[:, -1:]  # ä½¿ç”¨dynamicsé¢„æµ‹çš„è¾“å‡º
```

**ä¸ºä»€ä¹ˆé‡è¦**:
- è®­ç»ƒæ—¶: dynamicsé¢„æµ‹latent[:, t] â†’ latent[:, t+1]
- æ¨ç†æ—¶: åº”è¯¥ç”¨dynamicsé¢„æµ‹çš„latentä½œä¸ºèµ·ç‚¹,ä¿æŒä¸€è‡´æ€§
- ä¿®å¤å: contextâ†’predictionè¿‡æ¸¡æ›´å¹³æ»‘,å‡å°‘ä¸è¿ç»­æ€§

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1: Lossä¸ä¸‹é™

**ç—‡çŠ¶**: Train lossåœ¨é«˜å€¼plateau,ä¸ä¸‹é™

**å¯èƒ½åŸå› **:
1. Learning rateè¿‡é«˜æˆ–è¿‡ä½
2. ç¦»æ•£ç‰¹å¾è¢«é”™è¯¯æ ‡å‡†åŒ–
3. Input_dimä¸åŒ¹é…
4. Batch sizeå¤ªå°

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥å…ƒæ•°æ®
cat data/processed/metadata.json | grep -E "n_features|discrete_features"

# 2. é™ä½å­¦ä¹ ç‡
python src/training/train_world_model.py --learning_rate 1e-4

# 3. å¢åŠ batch size
python src/training/train_world_model.py --batch_size 64

# 4. æ£€æŸ¥æ—¥å¿—ä¸­çš„lossåˆ†é‡
tail -f logs/trainer.log
# å¦‚æœRecon losså¾ˆå¤§ â†’ encoder/decoderé—®é¢˜
# å¦‚æœPred losså¾ˆå¤§ â†’ dynamicsé—®é¢˜
# å¦‚æœExist losså¾ˆå¤§ â†’ decoder existence headé—®é¢˜
```

### é—®é¢˜2: Losså‡ºç°NaN

**ç—‡çŠ¶**: è®­ç»ƒå‡ ä¸ªepochålosså˜æˆNaN

**å¯èƒ½åŸå› **:
1. Learning rateè¿‡é«˜
2. Gradient explosion
3. æ•°å€¼ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. é™ä½å­¦ä¹ ç‡
python src/training/train_world_model.py --learning_rate 5e-4

# 2. æ·»åŠ gradient clipping (éœ€ä¿®æ”¹ä»£ç )
# åœ¨train_world_model.pyä¸­æ·»åŠ :
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# 3. æ£€æŸ¥æ•°æ®
python validate_preprocessing.py  # ç¡®ä¿æ•°æ®æ­£å¸¸
```

### é—®é¢˜3: é¢„æµ‹ä¸è¿ç»­

**ç—‡çŠ¶**: å¯è§†åŒ–ç»“æœä¸­,è“è‰²(context)å’Œçº¢è‰²(prediction)ä¹‹é—´æœ‰è·³è·ƒ

**åŸå› **: Rolloutèµ·ç‚¹é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**: âœ… å·²åœ¨2025-12-14ä¿®å¤!
```python
# src/models/world_model.py:191
# ç¡®ä¿ä½¿ç”¨dynamicsé¢„æµ‹çš„latentä½œä¸ºèµ·ç‚¹
current_latent = predicted_latent_context[:, -1:]
```

å¦‚æœä»æœ‰é—®é¢˜:
1. é‡æ–°è®­ç»ƒæ¨¡å‹(ä½¿ç”¨ä¿®å¤åçš„ä»£ç )
2. å¢åŠ context_length
3. è°ƒæ•´lossæƒé‡(å¢å¤§pred_weight)

### é—®é¢˜4: Collision Rateå¼‚å¸¸

**ç—‡çŠ¶**: Collision rate = 100%

**åŸå› **: safety_marginè®¾ç½®è¿‡å¤§

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®æ”¹src/evaluation/prediction_metrics.py:166
compute_collision_rate(predicted, masks, safety_margin=4.0)
# è°ƒæ•´ä¸ºåˆç†çš„è½¦è¾†å®½åº¦(3-5ç±³)
```

### é—®é¢˜5: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**: RuntimeError: size mismatch for dynamics.rnn.weight_ih_l0

**åŸå› **: æ¨¡å‹é…ç½®æ¨æ–­é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**: âœ… å·²åœ¨2025-12-14ä¿®å¤!

ç°åœ¨`src/evaluation/rollout_eval.py`ä¼šè‡ªåŠ¨:
1. ä»checkpointæ¨æ–­latent_dim
2. é€šè¿‡æƒé‡çŸ©é˜µå½¢çŠ¶æ¨æ–­dynamics_type (GRU vs LSTM)
3. æ¨æ–­hidden_dim

å¦‚æœä»æœ‰é—®é¢˜:
```bash
# æ‰‹åŠ¨æŒ‡å®šé…ç½® (éœ€ä¿®æ”¹ä»£ç æ·»åŠ å‚æ•°)
python src/evaluation/rollout_eval.py \
    --checkpoint xxx.pt \
    --latent_dim 512 \
    --dynamics_type lstm \
    --dynamics_hidden 512
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueså’ŒPull Requests!

**è´¡çŒ®æŒ‡å—**:
1. Forkæœ¬ä»“åº“
2. åˆ›å»ºfeatureåˆ†æ”¯
3. æäº¤æ›´æ”¹
4. å‘èµ·Pull Request

---

## ğŸ“„ è®¸å¯

MIT License

---

## ğŸ“® è”ç³»ä¸æ–‡æ¡£

**è¯¦ç»†æ–‡æ¡£**:
- ğŸ“˜ `CLAUDE.md` - è¯¦ç»†å¼€å‘æŒ‡å— (ä¸­æ–‡)
- ğŸ“˜ `WORLD_MODEL_COMPARISON.md` - ä¸DreamerV3æ¶æ„å¯¹æ¯”
- ğŸ“˜ `DEBUG_REPORT.md` - DebugæŠ¥å‘Š
- ğŸ“˜ `COMPLETE_DEBUG_SUMMARY_CN.md` - å®Œæ•´debugæ€»ç»“

**å¿«é€ŸæŸ¥æ‰¾**:
- å¦‚ä½•ä¿®æ”¹ç‰¹å¾? â†’ `src/data/preprocess.py:extract_extended_features`
- å¦‚ä½•ä¿®æ”¹æ¨¡å‹æ¶æ„? â†’ `src/models/encoder.py`, `decoder.py`, `dynamics.py`
- å¦‚ä½•ä¿®æ”¹loss? â†’ `src/training/losses.py`
- å¦‚ä½•æ·»åŠ æ–°æŒ‡æ ‡? â†’ `src/evaluation/prediction_metrics.py`

---

**é¡¹ç›®ç‰ˆæœ¬**: 1.0 (Production Ready âœ…)
**æœ€åæ›´æ–°**: 2025-12-14
**çŠ¶æ€**: æ‰€æœ‰å·²çŸ¥bugå·²ä¿®å¤
