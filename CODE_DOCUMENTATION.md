"""Traffic World Model - code documentation.

This repository evolved quickly and the previous function-by-function document
became stale. This file intentionally documents *entry points*, *data/layout
contracts*, and *behavioral gotchas* that affect training/eval correctness.
"""

# Traffic World Model - ä»£ç æ–‡æ¡£ï¼ˆç»´æŠ¤ç‰ˆï¼‰

## å…¥å£ä¸å·¥ä½œæµ

- é¢„å¤„ç†ï¼ˆraw CSV â†’ episodes.npzï¼‰: `src/data/preprocess_multisite.py`
- Dataset / DataLoader: `src/data/dataset.py`
- æ¨¡å‹ï¼ˆå« rollout & kinematic priorï¼‰: `src/models/world_model.py`
- è®­ç»ƒå…¥å£: `src/training/train_world_model.py`
- loss ç»„åˆä¸æƒé‡: `src/training/losses.py`
- rollout è¯„ä¼°: `src/evaluation/rollout_eval.py`
- æŒ‡æ ‡: `src/evaluation/prediction_metrics.py`
- å¯è§†åŒ–ï¼ˆé™æ€/åŠ¨ç”»ï¼‰:
  - `src/evaluation/visualize_predictions_detailed.py`
  - `src/evaluation/visualize_predictions_wm.py`

## æ•°æ®å¥‘çº¦ï¼ˆå¿…é¡»ä¸€è‡´çš„éƒ¨åˆ†ï¼‰

### æ—¶é—´ä¸å•ä½

- é»˜è®¤å¸§ç‡: 30 FPS
- é»˜è®¤å•ä½: åƒç´ ï¼ˆpixelï¼‰

### masks çš„è¯­ä¹‰

`masks[t, k] = 1` è¡¨ç¤º agent slot `k` åœ¨æ—¶é—´ `t` æœ‰æ•ˆã€‚
é‡è¦å½±å“:
- å·®åˆ†ï¼ˆä½ç½®â†’é€Ÿåº¦/åŠ é€Ÿåº¦ï¼‰è‹¥è·¨è¶Š mask gapï¼Œä¼šäº§ç”Ÿä¼ªé€Ÿåº¦ã€‚
- ç»˜å›¾è‹¥ä¸åœ¨ mask gap å¤„æ–­çº¿ï¼Œä¼šå‡ºç°â€œè¶…é•¿çº¿â€ä¼ªåƒã€‚

## é¢„å¤„ç†è¦ç‚¹

æ–‡ä»¶: `src/data/preprocess.py`

å…³é”®ç‚¹:
- ä¼šæ„å»ºå…¨å±€æ—¶é—´çº¿ï¼ˆé¿å…è·¨ CSV çš„ frame é‡ç½®ï¼‰å¹¶åš chronological splitã€‚
- é€Ÿåº¦/åŠ é€Ÿåº¦çš„å·®åˆ†åº”æŒ‰çœŸå®å¸§é—´éš”ï¼ˆframe gap * dtï¼‰ç¼©æ”¾ï¼Œå‡å¼±ç¼ºå¸§å¯¼è‡´çš„é€Ÿåº¦çˆ†ç‚¸ã€‚

æ–‡ä»¶: `src/data/preprocess_multisite.py`

å…³é”®ç‚¹:
- è´Ÿè´£å¤šç«™ç‚¹å¾ªç¯ã€splitã€ä¿å­˜ `train_episodes.npz/val_episodes.npz/test_episodes.npz` ä¸ `metadata.json`ã€‚

## Dataset ä¸ç‰¹å¾å¸ƒå±€

æ–‡ä»¶: `src/data/dataset.py`

æ ¸å¿ƒè¡Œä¸º:
- ä» `metadata.json` è¯»å–ç¦»æ•£ç‰¹å¾ç´¢å¼•ï¼ˆå¦‚ lane/class/site ç­‰ï¼‰ï¼Œå¹¶é¿å…å¯¹å…¶åš z-scoreã€‚
- ä¼šåŠ¨æ€è¿½åŠ  4 ä¸ªæ´¾ç”Ÿç‰¹å¾åˆ° state æœ«å°¾ï¼ˆæœ€ç»ˆ `states` ä¸º `[T, K, 24]`ï¼‰ã€‚
- val/test å¿…é¡»æ˜¾å¼æä¾› train çš„ `stats_path`ï¼Œé¿å…å½’ä¸€åŒ–ä¸ä¸€è‡´ã€‚

æ´¾ç”Ÿç‰¹å¾ï¼ˆæŒ‰ `__getitem__` é€»è¾‘ï¼‰:
- velocity_direction, headway, ttc, preceding_distance

## è®­ç»ƒä¸å…³é”®å¼€å…³

æ–‡ä»¶: `src/training/train_world_model.py`

### `--disable_vxy_supervision`

å«ä¹‰:
- vx/vy ä»ä½œä¸ºè¾“å…¥ç‰¹å¾å­˜åœ¨ï¼ˆæ¨¡å‹å¯ä½¿ç”¨ï¼‰ï¼Œä½†ä¸ä½œä¸ºå›å½’ç›‘ç£ç›®æ ‡ã€‚

åŸå› :
- vx/vy å¾ˆå®¹æ˜“è¢«ç¼ºå¸§/é‡ç°ï¼ˆmask 0â†’1ï¼‰å¼•å…¥çš„å·®åˆ†å™ªå£°æ±¡æŸ“ã€‚

é…å¥—è¡Œä¸º:
- vx/vy-based çš„ VEL-DIR æŒ‡æ ‡ä¼šåœ¨æ—¥å¿—é‡Œæ ‡æ³¨ä¸º diag-onlyã€‚
- open-loop rollout çš„ kinematic prior åœ¨è¯¥æ¨¡å¼ä¸‹ä¼šä¼˜å…ˆä½¿ç”¨ç”±é¢„æµ‹ä½ç½®å·®åˆ†å¾—åˆ°çš„é€Ÿåº¦ï¼ˆv = Î”p / dtï¼‰ï¼Œé¿å…ä¾èµ–æ¨¡å‹ç”Ÿæˆçš„ vx/vyã€‚

### short open-loop rollout loss

- ç”¨çŸ­ horizon çš„ open-loop rollout ä½ç½®è¯¯å·®ï¼ˆxy-onlyï¼‰ä½œä¸ºè¾…åŠ© lossï¼Œæ›´è´´è¿‘çœŸå® rollout è¡Œä¸ºã€‚

### scheduled sampling

- åœ¨ teacher forcing ä¸è‡ªå›å½’ä¹‹é—´åšå¹³æ»‘è¿‡æ¸¡ï¼Œé™ä½è®­ç»ƒ/æ¨ç†æš´éœ²åå·®ã€‚

### soft boundary penalty

- å¯¹è¶Šç•Œä½ç½®æ–½åŠ è½¯çº¦æŸï¼Œå‡å°‘ open-loop è·‘é£ã€‚

## è¯„ä¼°ä¸å¯è§†åŒ–

### æŒ‡æ ‡è®¡ç®—ç©ºé—´

æ–¹å‘/è§’åº¦ç›¸å…³æŒ‡æ ‡åº”åœ¨åå½’ä¸€åŒ–åçš„ç‰©ç†/åƒç´ ç©ºé—´è®¡ç®—ï¼Œé¿å…åœ¨å½’ä¸€åŒ–ç©ºé—´å› å„å‘å¼‚æ€§ std æ‰­æ›²è§’åº¦ã€‚

### mask-aware è½¨è¿¹ç»˜åˆ¶

å¯è§†åŒ–è„šæœ¬ä¼šåœ¨ mask gap å¤„æ’å…¥ NaN ä»¥æ–­çº¿ï¼Œé¿å… padding â†’ real çš„è¿æ¥å¯¼è‡´è¯¯è¯»ã€‚

## è°ƒè¯•è„šæœ¬ï¼ˆä¿ç•™åœ¨ src ä¸‹ï¼‰

ä¸ºé¿å…ä»“åº“æ ¹ç›®å½•å †ç§¯ä¸€æ¬¡æ€§è„šæœ¬ï¼Œæ–¹å‘ä¸€è‡´æ€§æ£€æŸ¥å·²è¿ç§»åˆ°:

- `src/evaluation/debug/gt_direction_consistency.py`
  4. ç¼–ç lanes (ä½¿ç”¨site-specific token: "A:A1")
  5. `detect_gaps_and_split_segments`
  6. **åº”ç”¨frame_rangeè¿‡æ»¤**:
     ```python
     for seg_start, seg_end in segments:
         clipped_start = max(seg_start, min_frame)
         clipped_end = min(seg_end, max_frame)
         if clipped_end - clipped_start + 1 >= episode_length:
             filtered_segments.append((clipped_start, clipped_end))
     ```
  7. `extract_fixed_stride_episodes`
- **è¿”å›**: (episodes, updated_lane_mapping)

#### è¾…åŠ©å‡½æ•°

**`extract_episodes(df, episode_length=30, overlap=0, ...) -> List[Dict]`**
- **ä½œç”¨**: æ—§ç‰ˆepisodeæå–(ä½¿ç”¨original frame,ä¸ä½¿ç”¨global timeline)
- **æ³¨**: å·²è¢«`extract_fixed_stride_episodes`æ›¿ä»£

**`extract_single_episode(df, frames, max_vehicles, ...) -> Dict`**
- **ä½œç”¨**: æ—§ç‰ˆå•episodeæå–(åŸºäºoriginal frame)
- **æ³¨**: å·²è¢«`extract_single_episode_from_global`æ›¿ä»£

**`compute_dataset_statistics(episodes: List[Dict]) -> Dict`**
- **ä½œç”¨**: è®¡ç®—æ•°æ®é›†ç»Ÿè®¡é‡
- **è¾“å‡º**:
  - `n_episodes`
  - `mean_vehicles_per_frame`
  - `max/min_vehicles_observed`
  - `feature_means/stds/mins/maxs` (per feature)

**`split_episodes(episodes, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42) -> Tuple[...]`**
- **ä½œç”¨**: éšæœºåˆ’åˆ†episodes (æ—§ç‰ˆ,å·²è¢«chronological splitæ›¿ä»£)
- **ç®—æ³•**: Random permutation â†’ æŒ‰æ¯”ä¾‹åˆ‡åˆ†
- **è¿”å›**: (train_episodes, val_episodes, test_episodes)

**`preprocess_trajectories(input_dir, output_dir, ...) -> None`**
- **ä½œç”¨**: æ—§ç‰ˆå®Œæ•´é¢„å¤„ç†æµç¨‹ (ä¸ä½¿ç”¨global timeline)
- **æ³¨**: ä¸»è¦ç”¨äºå‘åå…¼å®¹ï¼ˆå†…éƒ¨å‡½æ•°ï¼Œä¸ä½œä¸ºå¯¹å¤–CLIå…¥å£ï¼‰

> âœ… å”¯ä¸€æ¨è/æ”¯æŒçš„é¢„å¤„ç†å…¥å£æ˜¯ `src/data/preprocess_multisite.py`ï¼ˆè´Ÿè´£ multi-site + split + å†™å‡º `normalization_stats.npz`ï¼‰ã€‚

---

### ğŸ“„ `src/data/split_strategy.py`

æ•°æ®åˆ’åˆ†ç­–ç•¥,æ”¯æŒéšæœºåˆ’åˆ†å’Œæ—¶åºåˆ’åˆ†ã€‚

#### MultiSiteDataSplitterç±»

**`class MultiSiteDataSplitter`**
- **ä½œç”¨**: æ··åˆæ‰€æœ‰ç«™ç‚¹å¹¶éšæœºåˆ’åˆ†æ–‡ä»¶
- **ç”¨é€”**: æ—§ç‰ˆåˆ’åˆ†ç­–ç•¥(å·²è¢«chronological splitæ›¿ä»£)

**`__init__(raw_data_dir=None, sites=['A',...,'I'])`**
- **ä½œç”¨**: åˆå§‹åŒ–splitter
- **é€»è¾‘**: æ£€æŸ¥ç«™ç‚¹ç›®å½•æ˜¯å¦å­˜åœ¨,è®°å½•available_sites

**`get_site_files(site: str) -> List[Path]`**
- **ä½œç”¨**: è·å–æŒ‡å®šç«™ç‚¹çš„æ‰€æœ‰CSVæ–‡ä»¶
- **è¿”å›**: sorted list of CSV paths

**`split_data(train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42) -> Dict`**
- **ä½œç”¨**: éšæœºæ··åˆåˆ’åˆ†æ‰€æœ‰ç«™ç‚¹çš„æ–‡ä»¶
- **ç®—æ³•**:
  1. æ”¶é›†æ‰€æœ‰ç«™ç‚¹çš„æ‰€æœ‰CSVæ–‡ä»¶
  2. éšæœºshuffle (ä½¿ç”¨seed)
  3. æŒ‰æ¯”ä¾‹åˆ‡åˆ†: train=80%, val=10%, test=10%
- **è¿”å›**: `{'train': [files], 'val': [files], 'test': [files]}`

**`save_split_config(splits: Dict, output_path=None)`**
- **ä½œç”¨**: ä¿å­˜åˆ’åˆ†é…ç½®ä¸ºJSON (ç”¨äºå¤ç°)
- **æ ¼å¼**:
  ```json
  {
    "train": {
      "A": ["drone_1.csv", "drone_2.csv"],
      "B": [...]
    },
    "val": {...},
    "test": {...}
  }
  ```

#### æ—¶åºåˆ’åˆ†å‡½æ•°

**`chronological_split_episodes(episodes, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15) -> Dict`**
- **ä½œç”¨**: æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†episodes (é˜²æ­¢temporal leakage)
- **ç®—æ³•**:
  1. æŒ‰`episode_start_global_frame`æ’åº
  2. é¡ºåºåˆ‡åˆ†: first 70% â†’ train, next 15% â†’ val, last 15% â†’ test
- **å…³é”®**: ç¡®ä¿trainçš„æœ€æ™šæ—¶åˆ» < valçš„æœ€æ—©æ—¶åˆ»
- **è¿”å›**: `{'train': [...], 'val': [...], 'test': [...]}`
- **æ—¥å¿—**: æ‰“å°æ¯ä¸ªsplitçš„episodeæ•°å’ŒframeèŒƒå›´

---

### ğŸ“„ `src/data/dataset.py`

PyTorch Datasetå®ç°,ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚

#### TrajectoryDatasetç±»

**`class TrajectoryDataset(Dataset)`**
- **ä½œç”¨**: å¤šæ™ºèƒ½ä½“è½¨è¿¹episodeçš„PyTorch Dataset
- **æ•°æ®æ ¼å¼**:
  - `states`: [N, T, K, F] - Nä¸ªepisodes,æ¯ä¸ªT=80å¸§,K=50ä¸ªagents,F=12ç»´ç‰¹å¾
  - `masks`: [N, T, K] - æœ‰æ•ˆagentæ ‡è®° (1=æœ‰æ•ˆ, 0=padding)
  - `scene_ids`: [N] - ç«™ç‚¹ID (0-8 for A-I)

**`__init__(data_path, normalize=True, stats_path=None)`**
- **ä½œç”¨**: åˆå§‹åŒ–dataset
- **å…³é”®é€»è¾‘**:
  1. **å¼ºåˆ¶val/testä½¿ç”¨train stats**:
     ```python
     is_val_or_test = 'val' in filename or 'test' in filename
     if is_val_or_test and normalize and not stats_path:
         raise ValueError("Val/test MUST provide stats_path")
     ```
  2. åŠ è½½NPZæ•°æ® â†’ è½¬ä¸ºtorch.Tensor
  3. åŠ è½½metadata â†’ è¯†åˆ«discrete_features
  4. è®¡ç®—æˆ–åŠ è½½normalization stats (ä»…å¯¹continuous features)
  5. å½’ä¸€åŒ–æ•°æ®
  6. éªŒè¯å¹¶clampç¦»æ•£ç‰¹å¾
- **å‚æ•°**:
  - `data_path`: NPZæ–‡ä»¶è·¯å¾„
  - `normalize`: æ˜¯å¦å½’ä¸€åŒ–
  - `stats_path`: å½’ä¸€åŒ–ç»Ÿè®¡é‡è·¯å¾„ (val/testå¿…é¡»æä¾›)

**`_load_discrete_feature_indices() -> None`**
- **ä½œç”¨**: ä»metadata.jsonåŠ è½½ç¦»æ•£ç‰¹å¾ç´¢å¼•
- **é€»è¾‘**:
  ```python
  metadata = json.load('metadata.json')
  discrete_features = metadata['validation_info']['discrete_features']
  # {'lane_id': 8, 'class_id': 7, 'site_id': 11}
  self.discrete_indices = sorted([8, 7, 11])
  self.continuous_indices = [0,1,2,3,4,5,6,9,10]
  ```
- **è¾¹ç•Œ**: åŠ è½½num_lanes, num_sites, num_classesç”¨äºåç»­éªŒè¯

**`_validate_discrete_indices() -> None`**
- **ä½œç”¨**: éªŒè¯ç¦»æ•£ç‰¹å¾ç´¢å¼•çš„æœ‰æ•ˆæ€§
- **æ£€æŸ¥**:
  - ç´¢å¼•åœ¨[0, F-1]èŒƒå›´å†…
  - æ— é‡å¤
  - continuous + discrete = å®Œæ•´ç‰¹å¾é›†

**`_compute_stats() -> None`**
- **ä½œç”¨**: è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡é‡ (ä»…å¯¹continuous features)
- **ç®—æ³•**:
  ```python
  continuous_states = states[..., continuous_indices]  # [N,T,K,9]
  valid_continuous = continuous_states * masks.unsqueeze(-1)

  mean = valid_continuous.sum(dim=(0,1,2)) / n_valid  # [9]
  diff = (valid_continuous - mean) * masks.unsqueeze(-1)
  std = sqrt((diff**2).sum(dim=(0,1,2)) / n_valid)  # [9]
  std = clamp(std, min=1e-6)  # é˜²æ­¢é™¤é›¶
  ```
- **é‡è¦**: åªå¯¹continuous_indicesè®¡ç®—,discreteç‰¹å¾ä¸å‚ä¸

**`_load_stats(stats_path: str) -> None`**
- **ä½œç”¨**: ä»NPZæ–‡ä»¶åŠ è½½é¢„è®¡ç®—çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡
- **æ–‡ä»¶å†…å®¹**:
  ```python
  {
      'mean': [9],  # ä»…continuous features
      'std': [9],
      'continuous_indices': [0,1,2,3,4,5,6,9,10],
      'discrete_indices': [7,8,11]
  }
  ```

**`_normalize_data() -> None`**
- **ä½œç”¨**: å¯¹continuous featuresåº”ç”¨z-scoreå½’ä¸€åŒ–
- **ç®—æ³•**:
  ```python
  continuous_feats = states[..., continuous_indices]  # [N,T,K,9]
  continuous_feats = (continuous_feats - mean) / std
  continuous_feats = continuous_feats * masks.unsqueeze(-1)  # ç¡®ä¿padding=0
  states[..., continuous_indices] = continuous_feats
  # discrete featuresä¿æŒåŸå§‹æ•´æ•°å€¼ä¸å˜
  ```

**`_validate_and_clamp_discrete_features() -> None`**
- **ä½œç”¨**: éªŒè¯å¹¶ä¿®æ­£ç¦»æ•£ç‰¹å¾å€¼
- **æ“ä½œ**:
  1. Clampè´Ÿå€¼åˆ°0: `discrete_feat = clamp(discrete_feat, min=0)`
  2. è®¾ç½®paddingä½ç½®ä¸º0: `discrete_feat = discrete_feat * masks`
  3. æ£€æŸ¥æ˜¯å¦è¶…å‡ºèŒƒå›´ (è­¦å‘Šä½†ä¸æŠ¥é”™)
- **ç›®çš„**: ç¡®ä¿ç¦»æ•£å€¼æ˜¯æœ‰æ•ˆçš„embeddingç´¢å¼•

**`save_stats(save_path: str) -> None`**
- **ä½œç”¨**: ä¿å­˜å½’ä¸€åŒ–ç»Ÿè®¡é‡ä¾›val/testä½¿ç”¨
- **è¾“å‡º**: `normalization_stats.npz`

**`__len__() -> int`**
- **è¿”å›**: episodeæ•°é‡N

**`__getitem__(idx: int) -> Dict`**
- **ä½œç”¨**: è·å–å•ä¸ªepisode
- **è¿”å›**:
  ```python
  {
      'states': [T, K, F],  # float32, å½’ä¸€åŒ–çš„è¿ç»­+åŸå§‹ç¦»æ•£
      'masks': [T, K],      # float32
      'scene_id': int,      # int64
      'discrete_features': [T, K, n_discrete]  # int64, ç”¨äºembeddings
  }
  ```
- **å…³é”®**: æå–discrete_featuresä¸ºLongTensor,æ–¹ä¾¿embeddingå±‚ä½¿ç”¨

#### DataLoaderå·¥å‚å‡½æ•°

**`get_dataloader(data_path, batch_size=32, shuffle=True, num_workers=0, normalize=True, stats_path=None) -> DataLoader`**
- **ä½œç”¨**: åˆ›å»ºPyTorch DataLoader
- **å‚æ•°**:
  - `shuffle`: æ˜¯å¦shuffle (train=True, val/test=False)
  - `num_workers`: å¤šè¿›ç¨‹åŠ è½½ (Windowsé€šå¸¸ç”¨0)
  - `stats_path`: val/testå¿…é¡»æä¾›trainçš„statsè·¯å¾„
- **è¿”å›**: é…ç½®å¥½çš„DataLoader
- **ç”¨æ³•**:
  ```python
  train_loader = get_dataloader('train_episodes.npz', shuffle=True)
  val_loader = get_dataloader('val_episodes.npz', stats_path='train_stats.npz', shuffle=False)
  ```

---

## å·¥å…·æ¨¡å—

### ğŸ“„ `src/utils/common.py`

é€šç”¨å·¥å…·å‡½æ•°ã€‚

**`parse_discrete_feature_indices_from_metadata(metadata: dict) -> Tuple[List[int], Optional[int], Optional[int], Optional[int]]`**
- **ä½œç”¨**: ä» metadata ä¸­è§£æç¦»æ•£ç‰¹å¾ç´¢å¼• (é›†ä¸­åŒ–è§£æé€»è¾‘)
- **å‚æ•°**: metadata dict (åŒ…å« validation_info å­—æ®µ)
- **è¿”å›**: 
  ```python
  (
      discrete_indices: [7, 8, 11],  # sorted list
      idx_lane: 8,                    # lane_id index
      idx_class: 7,                   # class_id index  
      idx_site: 11                    # site_id index
  )
  ```
- **Fallback**: å¦‚æœ metadata ç¼ºå¤±å­—æ®µï¼Œè¿”å› `([7, 8, 11], 8, 7, 11)` (é»˜è®¤å€¼)
- **ç”¨é€”**: æ‰€æœ‰è®­ç»ƒ/è¯„ä¼°è„šæœ¬ä½¿ç”¨æ­¤å‡½æ•°ç»Ÿä¸€è§£æï¼Œé¿å…é‡å¤ä»£ç 
- **ä»£ç ä½ç½®**: `src/utils/common.py`
- **ç¤ºä¾‹**:
  ```python
  # åœ¨è®­ç»ƒè„šæœ¬ä¸­
  meta = train_loader.dataset.metadata
  discrete_indices, idx_lane, idx_class, idx_site = \
      parse_discrete_feature_indices_from_metadata(meta)
  
  # ä¼ é€’ç»™ WorldModel
  model = WorldModel(
      ...,
      lane_feature_idx=idx_lane,
      class_feature_idx=idx_class,
      site_feature_idx=idx_site
  )
  ```

**`set_seed(seed: int = 42)`**
- **ä½œç”¨**: è®¾ç½®æ‰€æœ‰éšæœºç§å­ç¡®ä¿å¯å¤ç°
- **è®¾ç½®**: random, numpy, torch (CPU + CUDA), cudnn

**`count_parameters(model: nn.Module) -> int`**
- **ä½œç”¨**: ç»Ÿè®¡æ¨¡å‹å¯è®­ç»ƒå‚æ•°æ•°é‡
- **è¿”å›**: å‚æ•°æ€»æ•°

**`get_device(device_id: Optional[int] = None) -> torch.device`**
- **ä½œç”¨**: è·å–PyTorchè®¾å¤‡
- **é€»è¾‘**: ä¼˜å…ˆä½¿ç”¨CUDA (å¦‚æœå¯ç”¨),å¦åˆ™CPU

**`save_config(config: dict, save_path: str)`**
- **ä½œç”¨**: ä¿å­˜é…ç½®å­—å…¸ä¸ºJSON

**`load_config(config_path: str) -> dict`**
- **ä½œç”¨**: ä»JSONåŠ è½½é…ç½®

**`format_time(seconds: float) -> str`**
- **ä½œç”¨**: æ ¼å¼åŒ–æ—¶é—´ä¸ºå¯è¯»å­—ç¬¦ä¸² (e.g., "1h 23m 45s")

**`compute_gradient_norm(model: nn.Module) -> float`**
- **ä½œç”¨**: è®¡ç®—æ¢¯åº¦çš„L2èŒƒæ•°
- **ç”¨é€”**: ç›‘æ§è®­ç»ƒç¨³å®šæ€§,æ¢¯åº¦çˆ†ç‚¸æ£€æµ‹

**`class EarlyStopping`**
- **ä½œç”¨**: Early stoppingå·¥å…·ç±»
- **æ–¹æ³•**:
  - `__init__(patience=10, min_delta=0, mode='min')`: åˆå§‹åŒ–
  - `__call__(metric_value) -> bool`: æ£€æŸ¥æ˜¯å¦åº”åœæ­¢è®­ç»ƒ
- **é€»è¾‘**: è¿ç»­patienceä¸ªepochæ²¡æœ‰æ”¹å–„åˆ™early_stop=True

**`get_pixel_to_meter_conversion(lane_geometry_path=None, default_value=0.077) -> float`**
- **ä½œç”¨**: è·å–åƒç´ åˆ°ç±³çš„è½¬æ¢å› å­
- **æ¥æº**: ä»lane_geometry_summary.jsonè¯»å– (å¦‚æœå­˜åœ¨)
- **é»˜è®¤**: 0.07696103842104474

**`convert_pixels_to_meters(states, pixel_to_meter, position_indices=(0,1), ...) -> Tensor`**
- **ä½œç”¨**: å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç±³
- **è½¬æ¢**:
  - ä½ç½®: `pixels * pixel_to_meter`
  - é€Ÿåº¦: `pixels/frame * pixel_to_meter` (å·²è€ƒè™‘dt)
  - åŠ é€Ÿåº¦: `pixels/frame^2 * pixel_to_meter` (å·²è€ƒè™‘dt)

---

### ğŸ“„ `src/utils/logger.py`

æ—¥å¿—å·¥å…·ã€‚

**`setup_logger(name='world_model', log_dir='./logs', log_file=None, level=logging.INFO) -> logging.Logger`**
- **ä½œç”¨**: é…ç½®logger,åŒæ—¶è¾“å‡ºåˆ°consoleå’Œæ–‡ä»¶
- **é…ç½®**:
  - Console handler (stdout)
  - File handler (ä¿å­˜åˆ°log_dir)
  - Formatter: `'%(asctime)s - %(name)s - %(levelname)s - %(message)s'`
- **è‡ªåŠ¨å‘½å**: å¦‚æœlog_file=None,ä½¿ç”¨`{name}_{timestamp}.log`

---

### ğŸ“„ `src/utils/config.py`

é…ç½®ç®¡ç†ç³»ç»Ÿ (åŸºäºdataclasså’ŒYAML)ã€‚

#### é…ç½®ç±»

**`@dataclass DataConfig`**
- **å­—æ®µ**: train_path, val_path, episode_length, max_agents, input_dim, normalize, stats_path

**`@dataclass ModelConfig`**
- **å­—æ®µ**: latent_dim, encoder_hidden, encoder_n_heads, encoder_n_layers, dynamics_type, dynamics_hidden, decoder_hidden

**`@dataclass TrainingConfig`**
- **å­—æ®µ**: batch_size, n_epochs, learning_rate, weight_decay, max_grad_norm, scheduler_type, use_amp, use_ddp

**`@dataclass LossConfig`**
- **å­—æ®µ**: reconstruction_weight, prediction_weight, existence_weight, huber_delta

**`@dataclass EvaluationConfig`**
- **å­—æ®µ**: context_length, rollout_length, horizons, eval_frequency, save_visualizations

**`@dataclass LoggingConfig`**
- **å­—æ®µ**: checkpoint_dir, log_dir, save_frequency, use_tensorboard, use_wandb

**`@dataclass ExperimentConfig`**
- **ä½œç”¨**: å®Œæ•´å®éªŒé…ç½®
- **åŒ…å«**: data, model, training, loss, evaluation, loggingå­é…ç½®

#### é…ç½®æ–¹æ³•

**`ExperimentConfig.from_yaml(yaml_path: str) -> ExperimentConfig`**
- **ä½œç”¨**: ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®

**`ExperimentConfig.from_dict(config_dict: Dict) -> ExperimentConfig`**
- **ä½œç”¨**: ä»å­—å…¸åˆ›å»ºé…ç½®

**`to_dict() -> Dict`**
- **ä½œç”¨**: è½¬æ¢ä¸ºå­—å…¸

**`to_yaml(save_path: str)`**
- **ä½œç”¨**: ä¿å­˜ä¸ºYAMLæ–‡ä»¶

**`to_json(save_path: str)`**
- **ä½œç”¨**: ä¿å­˜ä¸ºJSONæ–‡ä»¶

**`load_config(config_path: str) -> ExperimentConfig`**
- **ä½œç”¨**: ä»YAMLæˆ–JSONåŠ è½½é…ç½® (è‡ªåŠ¨æ£€æµ‹æ ¼å¼)

**`create_default_config(save_path='config.yaml')`**
- **ä½œç”¨**: åˆ›å»ºå¹¶ä¿å­˜é»˜è®¤é…ç½®æ¨¡æ¿

---

## è¯„ä¼°æ¨¡å—

### ğŸ“„ `src/evaluation/visualization.py`

è½¨è¿¹å¯è§†åŒ–å·¥å…·ã€‚

**`visualize_trajectories(predicted, ground_truth, masks, save_path=None, time_step=0, max_agents=20, figsize=(12,8))`**
- **ä½œç”¨**: å¯è§†åŒ–å•ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹vsçœŸå®è½¨è¿¹
- **ç»˜åˆ¶**:
  - ç»¿è‰²åœ†åœˆ: Ground truth
  - çº¢è‰²å‰å·: Prediction
  - è™šçº¿è¿æ¥: è¯¯å·®å‘é‡
- **è¾“å…¥**: [T, K, F] arrays

**`visualize_rollout(predicted, ground_truth, masks, save_path='rollout_comparison.png', max_agents=10, figsize=(10,4))`**
- **ä½œç”¨**: å¯¹æ¯”å®Œæ•´rolloutè½¨è¿¹
- **å¸ƒå±€**: å·¦å›¾GT,å³å›¾Prediction
- **ç»˜åˆ¶**: ä¸ºæ¯ä¸ªagentç”»è¿ç»­è½¨è¿¹çº¿

**`visualize_error_heatmap(predicted, ground_truth, masks, save_path=None, figsize=(12,6))`**
- **ä½œç”¨**: ç»˜åˆ¶è¯¯å·®çƒ­åŠ›å›¾ (æ—¶é—´Ã—agents)
- **è®¡ç®—**: L2 position error per (time, agent)
- **é¢œè‰²**: è¶Šçº¢è¯¯å·®è¶Šå¤§

**`plot_metrics_over_time(metrics_dict: dict, save_path=None, figsize=(12,8))`**
- **ä½œç”¨**: ç»˜åˆ¶metricséšé¢„æµ‹horizonå˜åŒ–
- **è¾“å…¥**: `{horizon: {metric_name: value}}`
- **ç»˜åˆ¶**: 2Ã—2å­å›¾,æ¯ä¸ªmetricä¸€æ¡æ›²çº¿

**`create_animation(predicted, ground_truth, masks, save_path, fps=10, max_agents=20)`**
- **ä½œç”¨**: åˆ›å»ºrolloutåŠ¨ç”» (GIFæˆ–MP4)
- **å®ç°**: ä½¿ç”¨matplotlib FuncAnimation
- **æ˜¾ç¤º**:
  - å½“å‰å¸§ä½ç½®
  - å†å²è½¨è¿¹trail
  - GT (ç»¿çº¿) vs Pred (çº¢è™šçº¿)

---

### ğŸ“„ `src/evaluation/attention_visualization.py`

æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–å’Œåˆ†æã€‚

**`visualize_attention_heatmap(attention_weights: [K,K], save_path=None, vehicle_ids=None, figsize=(12,10))`**
- **ä½œç”¨**: ç»˜åˆ¶agenté—´æ³¨æ„åŠ›çƒ­åŠ›å›¾
- **ä½¿ç”¨**: seaborn heatmap
- **è½´æ ‡ç­¾**: "Attending From (Query)" vs "Attending To (Key)"

**`visualize_spatial_attention(attention_weights: [K,K], positions: [K,2], query_idx=0, save_path=None, figsize=(10,10))`**
- **ä½œç”¨**: åœ¨ç©ºé—´åæ ‡ç³»ä¸­å¯è§†åŒ–æ³¨æ„åŠ›
- **ç»˜åˆ¶**:
  - Scatter: æ‰€æœ‰agents,é¢œè‰²è¡¨ç¤ºè¢«query agentæ³¨æ„çš„ç¨‹åº¦
  - è“è‰²æ˜Ÿå·: Query vehicle
  - ç®­å¤´: Top-Kæ³¨æ„åŠ›è¿æ¥,å®½åº¦âˆattention weight
  - æ ‡æ³¨: æ³¨æ„åŠ›æƒé‡æ•°å€¼

**`analyze_attention_patterns(attention_weights: [B,H,K,K], masks: [B,K], positions: [B,K,2]=None) -> Dict`**
- **ä½œç”¨**: åˆ†ææ³¨æ„åŠ›æ¨¡å¼,ç†è§£æ¨¡å‹å­¦ä¹ å†…å®¹
- **åˆ†ææŒ‡æ ‡**:
  - `avg_attention_per_head`: æ¯ä¸ªheadçš„å¹³å‡æ³¨æ„åŠ›
  - `attention_entropy`: æ³¨æ„åŠ›åˆ†å¸ƒçš„ç†µ (é«˜=åˆ†æ•£,ä½=é›†ä¸­)
  - `self_attention_ratio`: è‡ªæ³¨æ„åŠ›æ¯”ä¾‹
  - `avg_attended_vehicles`: å¹³å‡å…³æ³¨çš„vehicleæ•° (é˜ˆå€¼>0.1)
  - å¦‚æœæä¾›positions:
    - `attention_distance_correlation`: æ³¨æ„åŠ›ä¸è·ç¦»çš„ç›¸å…³æ€§
    - `attention_by_distance`: æŒ‰è·ç¦»binç»Ÿè®¡çš„å¹³å‡æ³¨æ„åŠ›

**`plot_attention_statistics(attention_analysis: Dict, save_path=None, figsize=(14,5))`**
- **ä½œç”¨**: ç»˜åˆ¶æ³¨æ„åŠ›åˆ†æç»Ÿè®¡å›¾
- **å¸ƒå±€**: 3ä¸ªå­å›¾
  1. æ¯ä¸ªheadçš„å¹³å‡æ³¨æ„åŠ› (æŸ±çŠ¶å›¾)
  2. å…³é”®æŒ‡æ ‡: Entropy, Self-Attention, Avg Attended (æŸ±çŠ¶å›¾)
  3. æ³¨æ„åŠ›vsè·ç¦» (æŠ˜çº¿å›¾)

**`extract_attention_from_model(model, states, masks, layer_idx=0) -> Tensor`**
- **ä½œç”¨**: ä»è®­ç»ƒå¥½çš„æ¨¡å‹æå–æ³¨æ„åŠ›æƒé‡
- **å®ç°**: ä½¿ç”¨hookæ•è·Transformerå±‚çš„attention
- **è¿”å›**: [B*T, H, K, K] attention weights

**`create_attention_report(model, dataloader, save_dir='./attention_analysis', n_samples=5, device='cpu')`**
- **ä½œç”¨**: ç”Ÿæˆå®Œæ•´çš„æ³¨æ„åŠ›åˆ†ææŠ¥å‘Š
- **è¾“å‡º**:
  - `attention_stats_sample_{i}.png`: ç»Ÿè®¡å›¾
  - `spatial_attention_sample_{i}.png`: ç©ºé—´æ³¨æ„åŠ›å›¾
- **æ ·æœ¬æ•°**: n_samplesä¸ªbatch

---

## æ¨¡å‹æ¶æ„æ¨¡å—

### ğŸ“„ `src/models/encoder.py`

å¤šæ™ºèƒ½ä½“ç¼–ç å™¨,ä½¿ç”¨Transformerè¿›è¡Œper-frameçš„agentäº¤äº’å»ºæ¨¡ã€‚

#### MultiAgentEncoderç±»

**`class MultiAgentEncoder(nn.Module)`**
- **ä½œç”¨**: å°†å¤šæ™ºèƒ½ä½“çŠ¶æ€ç¼–ç ä¸ºåœºæ™¯çº§latentè¡¨ç¤º
- **æ¶æ„**: è¿ç»­ç‰¹å¾æŠ•å½± + ç¦»æ•£ç‰¹å¾embedding â†’ Fusion â†’ Agent Transformer â†’ Masked Pooling â†’ Latent

**`__init__(...)`**
- **å‚æ•°**:
  - `input_dim=12`: è¾“å…¥ç‰¹å¾ç»´åº¦
  - `hidden_dim=256`: éšè—å±‚ç»´åº¦
  - `latent_dim=256`: è¾“å‡ºlatentç»´åº¦
  - `max_agents=50`: æœ€å¤§agentæ•°
  - `n_layers=2`: Transformerå±‚æ•°
  - `n_heads=8`: æ³¨æ„åŠ›å¤´æ•°
  - `dropout=0.1`: Dropoutç‡
  - ç¦»æ•£ç‰¹å¾é…ç½®:
    - `lane_feature_idx=8`: lane_idåœ¨featuresä¸­çš„ç´¢å¼•
    - `class_feature_idx=7`: class_idç´¢å¼•
    - `site_feature_idx=11`: site_idç´¢å¼•
    - `num_lanes=100`: lane vocabularyå¤§å°
    - `num_classes=10`: class vocabularyå¤§å°
    - `num_sites=10`: site vocabularyå¤§å°
    - `lane_embed_dim=16`, `class_embed_dim=8`, `site_embed_dim=8`: embeddingç»´åº¦
- **ç»„ä»¶**:
  1. **è¿ç»­ç‰¹å¾æŠ•å½±å™¨** (L69-74):
     ```python
     continuous_projector = Sequential(
         Linear(n_cont=9, hidden_dim=256),
         LayerNorm(256),
         ReLU(),
         Dropout(0.1)
     )
     ```
  2. **ç¦»æ•£ç‰¹å¾embeddings** (L76-89):
     - `lane_embedding`: nn.Embedding(num_lanes, 16)
     - `class_embedding`: nn.Embedding(num_classes, 8)
     - `site_embedding`: nn.Embedding(num_sites, 8)
  3. **ç‰¹å¾èåˆå±‚** (L91-96):
     ```python
     fusion = Sequential(
         Linear(fused_dim=256+16+8+8=288, hidden_dim=256),
         ReLU(),
         Dropout(0.1)
     )
     ```
  4. **Agent Transformer** (L98-106):
     - TransformerEncoder (d_model=256, nhead=8, dim_feedforward=1024)
     - batch_first=True, norm_first=True (Pre-LN)
     - n_layers=2
  5. **LatentæŠ•å½±** (L108-111):
     ```python
     to_latent = Sequential(
         Linear(256, latent_dim),
         LayerNorm(latent_dim)
     )
     ```

**`forward(states: [B,T,K,F], masks: [B,T,K]) -> [B,T,D]`**
- **æµç¨‹**:
  1. **ç»´åº¦æ£€æŸ¥** (L122-131): éªŒè¯statesä¸º[B,T,K,F], masksä¸º[B,T,K]
  2. **å±•å¹³æ—¶é—´ç»´åº¦** (L133-136):
     ```python
     states_flat = states.reshape(B*T, K, F)  # [B*T, K, F]
     masks_flat = masks.reshape(B*T, K)       # [B*T, K]
     pad = (masks_flat == 0)                  # [B*T, K] bool
     ```
  3. **è¿ç»­ç‰¹å¾å¤„ç†** (L138-140):
     ```python
     cont = states_flat[..., continuous_indices]  # [B*T, K, 9]
     cont_emb = continuous_projector(cont)         # [B*T, K, 256]
     ```
  4. **ç¦»æ•£ç‰¹å¾embedding** (L144-161):
     ```python
     # Lane embedding
     lane_ids = states_flat[..., 8].long()
     lane_ids = lane_ids.clamp(0, num_lanes-1)
     lane_ids = lane_ids.masked_fill(pad, 0)  # paddingä½ç½®è®¾ä¸º0
     lane_emb = lane_embedding(lane_ids)        # [B*T, K, 16]

     # åŒæ ·å¤„ç†class_idså’Œsite_ids
     ```
  5. **ç‰¹å¾æ‹¼æ¥ä¸èåˆ** (L163-164):
     ```python
     agent_feats = concat([cont_emb, lane_emb, class_emb, site_emb])  # [B*T,K,288]
     agent_feats = fusion(agent_feats)                                 # [B*T,K,256]
     ```
  6. **Agent Transformer** (L166-169):
     ```python
     agent_feats = agent_transformer(
         agent_feats,
         src_key_padding_mask=pad  # True=ignore this agent
     )  # [B*T, K, 256]
     ```
  7. **Masked Mean Pooling** (L171-173):
     ```python
     weights = masks_flat.unsqueeze(-1)  # [B*T, K, 1]
     pooled = (agent_feats * weights).sum(dim=1) / weights.sum(dim=1).clamp(min=1e-6)
     # pooled: [B*T, 256]
     ```
  8. **æŠ•å½±åˆ°latentç©ºé—´** (L175):
     ```python
     latent = to_latent(pooled).view(B, T, latent_dim)  # [B, T, D]
     ```
- **è¿”å›**: [B, T, latent_dim] åœºæ™¯çº§latentè¡¨ç¤º

---

### ğŸ“„ `src/models/dynamics.py`

åŸºäºTransformerçš„æ—¶åºåŠ¨åŠ›å­¦æ¨¡å‹ (Transformer-only)ã€‚

#### LatentDynamicsç±»

**`class LatentDynamics(nn.Module)`**
- **ä½œç”¨**: åœ¨latentç©ºé—´å»ºæ¨¡æ—¶åºæ¼”åŒ–
- **æ¶æ„**: Positional Encoding â†’ Causal Transformer â†’ Output Projection
- **å…³é”®ç‰¹æ€§**:
  - âœ… Transformer-only (ç§»é™¤äº†GRU/LSTM)
  - âœ… Causal masking: output[t]åªèƒ½attendåˆ°â‰¤tçš„å†å²
  - âœ… æ”¯æŒlearnedæˆ–sinusoidalä½ç½®ç¼–ç 
  - âœ… æ”¯æŒtime padding mask (å¿½ç•¥padding timesteps)

**`__init__(...)`**
- **å‚æ•°**:
  - `latent_dim=256`: latentç©ºé—´ç»´åº¦
  - `n_layers=4`: Transformerå±‚æ•°
  - `n_heads=8`: æ³¨æ„åŠ›å¤´æ•°
  - `dropout=0.1`: Dropoutç‡
  - `max_len=512`: æœ€å¤§åºåˆ—é•¿åº¦
  - `use_learned_pos_emb=True`: ä½¿ç”¨å¯å­¦ä¹ ä½ç½®ç¼–ç  (vs sinusoidal)
- **ç»„ä»¶**:
  1. **ä½ç½®ç¼–ç ** (L45-49):
     ```python
     if use_learned_pos_emb:
         pos_emb = Parameter(torch.zeros(1, max_len, latent_dim))
         nn.init.normal_(pos_emb, mean=0.0, std=0.02)
     else:
         pos_emb = _build_sinusoidal_pos_emb(max_len, latent_dim)
     ```
  2. **Transformer Encoder** (L51-59):
     - TransformerEncoderLayer (d_model=latent_dim, nhead=8, dim_feedforward=4*latent_dim)
     - batch_first=True, norm_first=True (Pre-LN)
     - num_layers=4
  3. **è¾“å‡ºæŠ•å½±** (L62-65):
     ```python
     output_proj = Sequential(
         LayerNorm(latent_dim),
         Linear(latent_dim, latent_dim)
     )
     ```

**`_build_sinusoidal_pos_emb(max_len, d_model) -> [1, max_len, d_model]`** (é™æ€æ–¹æ³•, L67-75)
- **ä½œç”¨**: æ„å»ºsinusoidalä½ç½®ç¼–ç 
- **ç®—æ³•**:
  ```python
  position = arange(max_len).unsqueeze(1)  # [max_len, 1]
  div_term = exp(arange(0, d_model, 2) * (-log(10000.0) / d_model))
  pe[:, 0::2] = sin(position * div_term)
  pe[:, 1::2] = cos(position * div_term)
  ```

**`_causal_mask(T, device, dtype) -> [T, T]`** (é™æ€æ–¹æ³•, L77-86)
- **ä½œç”¨**: ç”Ÿæˆcausal attention mask
- **ç®—æ³•**:
  ```python
  mask = full((T, T), -inf)
  mask = triu(mask, diagonal=1)  # Upper triangular (excluding diagonal) = -inf
  ```
- **å«ä¹‰**: ä½ç½®tåªèƒ½attendåˆ°ä½ç½®â‰¤t

**`forward(latent: [B,T,D], hidden=None, time_padding_mask: [B,T]=None) -> Tuple[[B,T,D], None]`**
- **æµç¨‹**:
  1. **æ·»åŠ ä½ç½®ç¼–ç ** (L114):
     ```python
     x = latent + pos_emb[:, :T, :]  # [B, T, D]
     ```
  2. **ç”Ÿæˆcausal mask** (L116):
     ```python
     causal = _causal_mask(T, device, dtype)  # [T, T]
     ```
  3. **Transformer forward** (L118-122):
     ```python
     out = transformer(
         x,
         mask=causal,  # causal attention
         src_key_padding_mask=time_padding_mask  # [B,T] å¿½ç•¥padding timesteps
     )  # [B, T, D]
     ```
  4. **è¾“å‡ºæŠ•å½±** (L124):
     ```python
     out = output_proj(out)  # [B, T, D]
     ```
- **è¿”å›**: (predicted_latent [B,T,D], None)
- **æ³¨**: predicted_latent[:, t]é¢„æµ‹æ—¶åˆ»t+1çš„latent (one-step-ahead)

**`step(latent_history: [B,T,D], time_padding_mask=None, max_context=None) -> [B,D]`** (@torch.no_grad(), L127-154)
- **ä½œç”¨**: ä½¿ç”¨å®Œæ•´(æˆ–truncated)å†å²è¿›è¡Œå•æ­¥é¢„æµ‹
- **ç”¨é€”**: Rolloutæ—¶ä½¿ç”¨
- **æµç¨‹**:
  1. **Truncateå†å²** (L148-151):
     ```python
     if max_context and latent_history.size(1) > max_context:
         latent_history = latent_history[:, -max_context:, :]
         time_padding_mask = time_padding_mask[:, -max_context:]
     ```
  2. **Forward** (L153):
     ```python
     pred, _ = forward(latent_history, time_padding_mask=time_padding_mask)
     ```
  3. **è¿”å›æœ€åä¸€ä¸ªtokençš„é¢„æµ‹** (L154):
     ```python
     return pred[:, -1, :]  # [B, D] é¢„æµ‹ä¸‹ä¸€æ­¥latent
     ```

---

### ğŸ“„ `src/models/decoder.py`

çŠ¶æ€è§£ç å™¨,ä»latentè§£ç ä¸ºçŠ¶æ€å’Œå­˜åœ¨æ€§ã€‚

#### StateDecoderç±»

**`class StateDecoder(nn.Module)`**
- **ä½œç”¨**: å°†latentè§£ç ä¸ºagent stateså’Œexistence logits
- **æ¶æ„**: MLP Backbone â†’ State Head + Existence Head + (å¯é€‰)Residual XY Head
- **å…³é”®ç‰¹æ€§**:
  - âœ… è¾“å‡ºç»å¯¹çŠ¶æ€ (åœ¨å½’ä¸€åŒ–ç©ºé—´)
  - âœ… å­˜åœ¨æ€§logits (ç”¨sigmoidè½¬ä¸ºæ¦‚ç‡)
  - âœ… å¯é€‰(x,y)æ®‹å·®å¤´ (ç”¨äºç‰©ç†å…ˆéªŒä¿®æ­£)

**`__init__(...)`**
- **å‚æ•°**:
  - `latent_dim=256`: è¾“å…¥latentç»´åº¦
  - `hidden_dim=256`: éšè—å±‚ç»´åº¦
  - `output_dim=12`: è¾“å‡ºçŠ¶æ€ç»´åº¦ (F=12)
  - `max_agents=50`: æœ€å¤§agentæ•°
  - `dropout=0.1`: Dropoutç‡
  - `enable_xy_residual=True`: æ˜¯å¦å¯ç”¨(x,y)æ®‹å·®å¤´
- **ç»„ä»¶**:
  1. **MLP Backbone** (L34-42):
     ```python
     backbone = Sequential(
         Linear(latent_dim, hidden_dim),
         LayerNorm(hidden_dim),
         ReLU(),
         Dropout(0.1),
         Linear(hidden_dim, hidden_dim),
         ReLU(),
         Dropout(0.1)
     )
     ```
  2. **State Head** (L45):
     ```python
     state_head = Linear(hidden_dim, max_agents * output_dim)
     ```
  3. **Existence Head** (L48):
     ```python
     existence_head = Linear(hidden_dim, max_agents)
     ```
  4. **Residual XY Head** (L51-57, å¯é€‰):
     ```python
     if enable_xy_residual:
         residual_xy_head = Linear(hidden_dim, max_agents * 2)
         # âœ… åˆå§‹åŒ–ä¸º0: ä»çº¯ç‰©ç†å…ˆéªŒå¼€å§‹å­¦ä¹ 
         nn.init.zeros_(residual_xy_head.weight)
         nn.init.zeros_(residual_xy_head.bias)
     ```

**`forward(latent: [B,T,D], return_residual_xy=False) -> Tuple[[B,T,K,F], [B,T,K], Optional[[B,T,K,2]]]`**
- **æµç¨‹**:
  1. **Backbone** (L81):
     ```python
     h = backbone(latent)  # [B, T, hidden_dim]
     ```
  2. **Stateé¢„æµ‹** (L83):
     ```python
     states = state_head(h).view(B, T, max_agents, output_dim)  # [B,T,K,F]
     ```
  3. **Existence logits** (L84):
     ```python
     existence_logits = existence_head(h)  # [B, T, K]
     ```
  4. **å¯é€‰: Residual XY** (L86-90):
     ```python
     if return_residual_xy:
         residual_xy = residual_xy_head(h).view(B, T, max_agents, 2)  # [B,T,K,2]
     else:
         residual_xy = None
     ```
- **è¿”å›**: (states, existence_logits, residual_xy)

---

### ğŸ“„ `src/models/world_model.py`

å®Œæ•´çš„World Model: Encoder â†’ Transformer Dynamics â†’ Decoder (with Kinematic Prior)ã€‚

#### WorldModelç±»

**`class WorldModel(nn.Module)`**
- **ä½œç”¨**: ç»„è£…å®Œæ•´çš„world model
- **æ¶æ„**: MultiAgentEncoder â†’ LatentDynamics (Transformer) â†’ StateDecoder
- **æ ¸å¿ƒåˆ›æ–°**: ğŸ”¥ **Kinematic Prior + Residual** ç”¨äº(x,y)é¢„æµ‹

**`__init__(...)`**
- **å‚æ•°**:
  - `input_dim=12`, `max_agents=50`, `latent_dim=256`
  - `dynamics_layers=4`, `dynamics_heads=8`
  - `dt=1.0/30`: æ—¶é—´æ­¥é•¿ (ç§’)
  - `max_dynamics_len=512`: Transformeræœ€å¤§åºåˆ—é•¿åº¦
  - `max_dynamics_context=128`: Rolloutæ—¶æˆªæ–­ä¸Šä¸‹æ–‡é•¿åº¦
  - ç‰¹å¾ç´¢å¼•: `idx_x=0`, `idx_y=1`, `idx_vx=2`, `idx_vy=3`, `idx_ax=4`, `idx_ay=5`
  - ğŸ”¥ `idx_angle=6`: **angleç‰¹å¾ç´¢å¼•** (æ–°å¢)
  - `use_acceleration=True`: æ˜¯å¦ä½¿ç”¨åŠ é€Ÿåº¦
  - Embeddingé…ç½®: `num_lanes`, `num_sites`, `num_classes`, å„è‡ªçš„`embed_dim`
- **ç»„ä»¶åˆå§‹åŒ–**:
  1. **Encoder** (L71-85): MultiAgentEncoder
  2. **Dynamics** (L88-93): LatentDynamics (Transformer-only)
  3. **Decoder** (L96-102): StateDecoder (enable_xy_residual=True, ğŸ”¥ enable_angle_head=True)
  4. **Normalization buffers** (L105-108):
     ```python
     register_buffer("norm_mean_cont", zeros(1))
     register_buffer("norm_std_cont", ones(1))
     register_buffer("cont_index_map", full((input_dim,), -1, dtype=long))
     ```

**`set_normalization_stats(mean_cont, std_cont, continuous_indices) -> None`** (L110-126)
- **ä½œç”¨**: è®¾ç½®å½’ä¸€åŒ–ç»Ÿè®¡é‡ (ç”¨äºkinematic priorçš„denorm/renorm)
- **å‚æ•°**:
  - `mean_cont`: [n_continuous] è¿ç»­ç‰¹å¾çš„mean
  - `std_cont`: [n_continuous] è¿ç»­ç‰¹å¾çš„std
  - `continuous_indices`: è¿ç»­ç‰¹å¾çš„ç´¢å¼•åˆ—è¡¨
- **é€»è¾‘**:
  ```python
  norm_mean_cont = tensor(mean_cont)  # [n_cont]
  norm_std_cont = tensor(std_cont).clamp(min=1e-6)

  # åˆ›å»ºfeature_idx â†’ continuous_idxçš„æ˜ å°„
  cont_index_map = full((input_dim,), -1)
  for j, feat_idx in enumerate(continuous_indices):
      cont_index_map[feat_idx] = j
  ```

**`_require_stats(feat_idx) -> (mean, std)`** (L128-140)
- **ä½œç”¨**: è·å–æŒ‡å®šç‰¹å¾çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡
- **è¿”å›**: (meanæ ‡é‡, stdæ ‡é‡)

**`_denorm(x_norm, feat_idx) -> x_raw`** (L142-144)
- **ä½œç”¨**: åå½’ä¸€åŒ–: `x_raw = x_norm * std + mean`

**`_renorm(x_raw, feat_idx) -> x_norm`** (L146-148)
- **ä½œç”¨**: å½’ä¸€åŒ–: `x_norm = (x_raw - mean) / std`

**`_kinematic_prior_xy(prev_states: [B,T,K,F]) -> [B,T,K,2]`** (L150-171)
- **ä½œç”¨**: ğŸ”¥ è®¡ç®—è¿åŠ¨å­¦å…ˆéªŒ (åœ¨åŸå§‹ç©ºé—´)
- **ç®—æ³•**:
  ```python
  # 1. Denormalizeåˆ°åŸå§‹ç©ºé—´
  x = _denorm(prev_states[..., idx_x], idx_x)
  y = _denorm(prev_states[..., idx_y], idx_y)
  vx = _denorm(prev_states[..., idx_vx], idx_vx)
  vy = _denorm(prev_states[..., idx_vy], idx_vy)

  # 2. åº”ç”¨è¿åŠ¨å­¦æ–¹ç¨‹
  if use_acceleration:
      ax = _denorm(prev_states[..., idx_ax], idx_ax)
      ay = _denorm(prev_states[..., idx_ay], idx_ay)
      x_next = x + vx*dt + 0.5*ax*dt^2
      y_next = y + vy*dt + 0.5*ay*dt^2
  else:
      x_next = x + vx*dt
      y_next = y + vy*dt

  # 3. Renormalizeå›å½’ä¸€åŒ–ç©ºé—´
  x_next_norm = _renorm(x_next, idx_x)
  y_next_norm = _renorm(y_next, idx_y)
  return stack([x_next_norm, y_next_norm], dim=-1)  # [B,T,K,2]
  ```
- **å…³é”®**: ç‰©ç†è®¡ç®—åœ¨åŸå§‹ç©ºé—´è¿›è¡Œ,ç¡®ä¿æ­£ç¡®æ€§

ğŸ”¥ **`_kinematic_prior_angle(prev_states: [B,T,K,F]) -> [B,T,K]`** (æ–°å¢)
- **ä½œç”¨**: è®¡ç®—angleçš„ç‰©ç†å…ˆéªŒ (åŸºäºé€Ÿåº¦æ–¹å‘)
- **ç®—æ³•**:
  ```python
  # 1. Denormalizeé€Ÿåº¦
  vx = _denorm(prev_states[..., idx_vx], idx_vx)
  vy = _denorm(prev_states[..., idx_vy], idx_vy)
  
  # 2. è®¡ç®—é€Ÿåº¦æ–¹å‘è§’ (å³æœå‘è§’çš„å…ˆéªŒ)
  angle_prior = torch.atan2(vy, vx)  # [-Ï€, Ï€]
  
  # 3. ä¸éœ€è¦ renormalize (å› ä¸º angle ä¸è¢«å½’ä¸€åŒ–)
  return angle_prior  # [B,T,K]
  ```
- **ç‰©ç†æ„ä¹‰**: è½¦è¾†æœå‘ â‰ˆ é€Ÿåº¦æ–¹å‘ (å¾ˆå¼ºçš„ç‰©ç†çº¦æŸ)
- **å¤„ç†è¾¹ç•Œ**: å½“ `vx â‰ˆ 0, vy â‰ˆ 0` æ—¶ `atan2` ä»ç„¶æœ‰å®šä¹‰ (è¿”å›0)
- **ä½¿ç”¨**: åœ¨ `forward()` ä¸­ä¸ decoder é¢„æµ‹æ··åˆ

**`forward(states: [B,T,K,F], masks: [B,T,K]) -> Dict`** (L173-215)
- **ä½œç”¨**: æ¨¡å‹å‰å‘ä¼ æ’­
- **æµç¨‹**:
  1. **ç¼–ç ** (L190):
     ```python
     latent = encoder(states, masks)  # [B, T, D]
     ```
  2. **Time padding mask** (L193):
     ```python
     time_padding = (masks.sum(dim=-1) == 0)  # [B, T] bool
     # True=è¯¥æ—¶é—´æ­¥æ‰€æœ‰agentéƒ½ä¸å­˜åœ¨
     ```
  3. **Dynamicsé¢„æµ‹** (L195):
     ```python
     predicted_latent, _ = dynamics(latent, time_padding_mask=time_padding)
     ```
  4. **é‡å»ºåˆ†æ”¯è§£ç ** (L197):
     ```python
     recon_states, exist_logits, _ = decoder(latent, return_residual_xy=False)
     ```
  5. **é¢„æµ‹åˆ†æ”¯è§£ç  (with residual)** (L198):
     ```python
     pred_states_base, pred_exist_logits, residual_xy = decoder(
         predicted_latent,
         return_residual_xy=True
     )
     ```
  6. **ğŸ”¥ åº”ç”¨Kinematic Prior + Residual** (L200-207):
     ```python
     pred_states = pred_states_base.clone()
     if residual_xy is not None:
         prior_xy = _kinematic_prior_xy(states)  # [B,T,K,2] té¢„æµ‹t+1çš„prior
         residual_xy = residual_xy * masks.unsqueeze(-1)  # mask padding
         pred_states[..., idx_x] = prior_xy[..., 0] + residual_xy[..., 0]
         pred_states[..., idx_y] = prior_xy[..., 1] + residual_xy[..., 1]
     # å…¶ä»–ç‰¹å¾ç›´æ¥ä½¿ç”¨decoderè¾“å‡º
     ```
- **è¿”å›**:
  ```python
  {
      "latent": [B,T,D],
      "reconstructed_states": [B,T,K,F],
      "predicted_states": [B,T,K,F],  # with prior+residual
      "existence_logits": [B,T,K],
      "predicted_existence_logits": [B,T,K]
  }
  ```

**`rollout(initial_states: [B,T0,K,F], initial_masks: [B,T0,K], n_steps=20, threshold=0.5, teacher_forcing=False, ground_truth_states=None) -> Tuple[[B,n_steps,K,F], [B,n_steps,K]]`** (@torch.no_grad(), L217-296)
- **ä½œç”¨**: ğŸš€ Open-loop rollouté¢„æµ‹
- **å‚æ•°**:
  - `initial_states/masks`: Context (é€šå¸¸T0=65)
  - `n_steps`: é¢„æµ‹æ­¥æ•° (é€šå¸¸H=15)
  - `threshold=0.5`: å­˜åœ¨æ€§é˜ˆå€¼
  - `teacher_forcing`: æ˜¯å¦ä½¿ç”¨ground truthä½œä¸ºprev
  - `ground_truth_states`: [B,T0+n_steps,K,F] (teacher forcingæ—¶éœ€è¦)
- **æµç¨‹**:
  1. **ç¼–ç context** (L243-244):
     ```python
     latent_ctx = encoder(initial_states, initial_masks)  # [B,T0,D]
     time_padding = (initial_masks.sum(dim=-1) == 0)
     ```
  2. **Dynamicsé¢„æµ‹context** (L246-247):
     ```python
     pred_latent_ctx, _ = dynamics(latent_ctx, time_padding_mask=time_padding)
     current_latent = pred_latent_ctx[:, -1:, :]  # [B,1,D] æœ€åä¸€æ­¥çš„é¢„æµ‹
     ```
  3. **åˆå§‹åŒ–å†å²å’ŒçŠ¶æ€** (L249-250):
     ```python
     latent_hist = latent_ctx  # [B, T0, D]
     prev_state = initial_states[:, -1:, :, :]  # [B, 1, K, F]
     ```
  4. **Autoregressive rolloutå¾ªç¯** (L255-292):
     ```python
     for step in range(n_steps):
         # a. è§£ç å½“å‰latent
         base_states, exist_logits, residual_xy = decoder(
             current_latent, return_residual_xy=True
         )
         pred_state = base_states.clone()

         # b. ğŸ”¥ åº”ç”¨kinematic prior
         prior_xy = _kinematic_prior_xy(prev_state)  # åŸºäºprev_stateé¢„æµ‹
         if residual_xy:
             pred_state[..., idx_x] = prior_xy[..., 0] + residual_xy[..., 0]
             pred_state[..., idx_y] = prior_xy[..., 1] + residual_xy[..., 1]

         # c. å­˜åœ¨æ€§mask
         exist_prob = sigmoid(exist_logits)
         pred_mask = (exist_prob > threshold).float()

         out_states.append(pred_state)
         out_masks.append(pred_mask)

         # d. å†³å®šä¸‹ä¸€æ­¥çš„"prev_state"
         if teacher_forcing and ground_truth_states:
             gt_state = ground_truth_states[:, T0+step:T0+step+1, :, :]
             prev_state = gt_state
             current_latent = encoder(gt_state, gt_mask)
         else:
             prev_state = pred_state * pred_mask.unsqueeze(-1)

         # e. ç´¯ç§¯latentå†å²,é¢„æµ‹ä¸‹ä¸€æ­¥
         latent_hist = cat([latent_hist, current_latent], dim=1)
         next_latent = dynamics.step(
             latent_hist,
             max_context=max_dynamics_context  # 128 truncate
         ).view(B, 1, -1)
         current_latent = next_latent
     ```
  5. **æ‹¼æ¥è¾“å‡º** (L294-296):
     ```python
     predicted_states = cat(out_states, dim=1)  # [B, n_steps, K, F]
     predicted_masks = cat(out_masks, dim=1)    # [B, n_steps, K]
     ```
- **è¿”å›**: (predicted_states, predicted_masks)
- **å…³é”®ç‰¹æ€§**:
  - ä½¿ç”¨`dynamics.step()`è¿›è¡Œå•æ­¥é¢„æµ‹
  - Truncated context (max_context=128) é¿å…å†…å­˜çˆ†ç‚¸
  - æ¯æ­¥åº”ç”¨kinematic prior + residual

---

---

## è®­ç»ƒæ¨¡å—

### ğŸ“„ `src/training/losses.py`

World Modelçš„Losså‡½æ•°å®ç°ã€‚

#### WorldModelLossç±»

**`class WorldModelLoss(nn.Module)`**
- **ä½œç”¨**: è®¡ç®—world modelçš„æ€»loss
- **ç»„æˆ**: Reconstruction Loss + Prediction Loss + Existence Loss
- **å…³é”®**: âš ï¸ **åªå¯¹continuous featuresè®¡ç®—å›å½’loss,discrete featuresä¸å‚ä¸**

**`__init__(...)`**
- **å‚æ•°**:
  - `recon_weight=1.0`: é‡å»ºlossæƒé‡
  - `pred_weight=1.0`: é¢„æµ‹lossæƒé‡
  - `exist_weight=0.1`: å­˜åœ¨æ€§lossæƒé‡
  - `huber_beta=1.0`: Huber lossçš„betaå‚æ•°
  - `continuous_indices`: **å…³é”®**! è¿ç»­ç‰¹å¾ç´¢å¼•åˆ—è¡¨ (e.g., [0,1,2,3,4,5,6,9,10])
  - `use_pred_existence_loss=True`: æ˜¯å¦è®¡ç®—é¢„æµ‹åˆ†æ”¯çš„å­˜åœ¨æ€§loss

**`_masked_huber_loss(pred: [B,T,K,F], target: [B,T,K,F], mask: [B,T,K]) -> scalar`** (L39-57)
- **ä½œç”¨**: è®¡ç®—masked Huber loss (ä»…å¯¹continuous features)
- **ç®—æ³•**:
  ```python
  # 1. è¿‡æ»¤åˆ°continuous features
  if continuous_indices is not None:
      pred = pred[..., continuous_indices]     # [B,T,K,9]
      target = target[..., continuous_indices] # [B,T,K,9]

  # 2. SmoothL1 Loss (Huber)
  diff = pred - target
  abs_diff = diff.abs()
  beta = huber_beta  # 1.0
  loss = where(
      abs_diff < beta,
      0.5 * (diff ** 2) / beta,  # å°è¯¯å·®: quadratic
      abs_diff - 0.5 * beta       # å¤§è¯¯å·®: linear (robust to outliers)
  )

  # 3. åº”ç”¨mask
  loss = loss * mask.unsqueeze(-1)  # [B,T,K,9]

  # 4. å½’ä¸€åŒ–
  denom = mask.sum() * loss.shape[-1]  # æœ‰æ•ˆagentæ•° Ã— featureæ•°
  return loss.sum() / denom.clamp(min=1.0)
  ```
- **ä¸ºä»€ä¹ˆHuber**: ç›¸æ¯”MSE,å¯¹outliersæ›´robust

**`_existence_loss(logits: [B,T,K], mask: [B,T,K]) -> scalar`** (L59-65)
- **ä½œç”¨**: è®¡ç®—å­˜åœ¨æ€§BCE loss
- **ç®—æ³•**:
  ```python
  loss = BCEWithLogitsLoss(logits, mask)
  # mask: 1=agentå­˜åœ¨, 0=padding
  return loss.mean()
  ```

ğŸ”¥ **`_angular_distance(pred_angle: [B,T,K], target_angle: [B,T,K]) -> [B,T,K]`** (static, æ–°å¢)
- **ä½œç”¨**: è®¡ç®—å‘¨æœŸæ€§è§’åº¦è·ç¦» (å¤„ç† `-Ï€` å’Œ `Ï€` çš„ç­‰ä»·æ€§)
- **ç®—æ³•**:
  ```python
  diff = pred_angle - target_angle  # å¯èƒ½è¶…å‡º [-Ï€, Ï€]
  
  # å°†å·®å€¼æ˜ å°„åˆ° [-Ï€, Ï€]
  distance = torch.atan2(torch.sin(diff), torch.cos(diff))
  # atan2(sin, cos) è‡ªåŠ¨å¤„ç†å‘¨æœŸæ€§
  
  return distance.abs()  # [B,T,K] éè´Ÿè·ç¦»
  ```
- **ä¾‹å­**:
  - `pred=3.0, target=-3.0`: ä¼ ç»ŸL1=6.0, angular distance=0.28 âœ…
  - `pred=0.0, target=3.14`: ä¼ ç»ŸL1=3.14, angular distance=3.14 âœ…
  - `pred=-3.1, target=3.1`: ä¼ ç»ŸL1=6.2, angular distance=0.08 âœ…
- **ä¼˜åŠ¿**: æ­£ç¡®å¤„ç†è§’åº¦çš„å‘¨æœŸæ€§ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸

ğŸ”¥ **`_angular_loss(pred_angle: [B,T,K], target_angle: [B,T,K], mask: [B,T,K]) -> scalar`** (æ–°å¢)
- **ä½œç”¨**: è®¡ç®—masked angular distance loss
- **ç®—æ³•**:
  ```python
  distance = _angular_distance(pred_angle, target_angle)  # [B,T,K]
  
  # åº”ç”¨mask
  masked_distance = distance * mask  # [B,T,K]
  
  # å¹³å‡
  loss = masked_distance.sum() / mask.sum().clamp(min=1.0)
  return loss
  ```
- **è¿”å›**: å¹³å‡è§’åº¦è¯¯å·® (å¼§åº¦)

**`forward(predictions: Dict, targets: Dict) -> Dict`** (L67-109)
- **ä½œç”¨**: è®¡ç®—æ€»losså’Œå„åˆ†é¡¹
- **è¾“å…¥**:
  - `targets`: `{'states': [B,T,K,F], 'masks': [B,T,K]}`
  - `predictions`: ä»WorldModel.forward()çš„è¾“å‡º
- **æµç¨‹**:
  1. **é‡å»ºloss** (L86): å¯¹é½tä¸t
     ```python
     recon_loss = _masked_huber_loss(
         reconstructed_states,  # [B, T, K, F]
         states,                # [B, T, K, F]
         masks                  # [B, T, K]
     )
     ```
  2. **é¢„æµ‹loss** (L89): té¢„æµ‹t+1,å¿½ç•¥æœ€åä¸€æ­¥
     ```python
     pred_loss = _masked_huber_loss(
         pred_states[:, :-1],   # [B, T-1, K, F] é¢„æµ‹: t=0åˆ°T-2
         states[:, 1:],         # [B, T-1, K, F] ç›®æ ‡: t=1åˆ°T-1
         masks[:, :-1]          # [B, T-1, K]
     )
     ```
     **å…³é”®**: æ—¶é—´å¯¹é½! pred_states[:, t]é¢„æµ‹states[:, t+1]
  3. **å­˜åœ¨æ€§loss (é‡å»ºåˆ†æ”¯)** (L91):
     ```python
     exist_loss = _existence_loss(existence_logits, masks)
     ```
  4. **å­˜åœ¨æ€§loss (é¢„æµ‹åˆ†æ”¯)** (L93-95):
     ```python
     if use_pred_existence_loss:
         pred_exist_loss = _existence_loss(
             predicted_existence_logits[:, :-1],  # t=0åˆ°T-2
             masks[:, 1:]                         # t=1åˆ°T-1
         )
     ```
  5. **æ€»loss** (L97-101):
     ```python
     total = (
         recon_weight * recon_loss +
         pred_weight * pred_loss +
         exist_weight * (exist_loss + pred_exist_loss)
     )
     ```
- **è¿”å›**:
  ```python
  {
      "total_loss": total,                      # ç”¨äºbackward
      "recon_loss": recon_loss.detach(),        # ç›‘æ§ç”¨
      "pred_loss": pred_loss.detach(),
      "exist_loss": exist_loss.detach(),
      "pred_exist_loss": pred_exist_loss.detach()
  }
  ```

**ä¸ºä»€ä¹ˆåªå¯¹continuous featuresè®¡ç®—loss**:
```
ç¦»æ•£ç‰¹å¾ (7=class_id, 8=lane_id, 11=site_id):
- æ˜¯ç±»åˆ«å˜é‡,ä¸åº”è¯¥ç”¨å›å½’loss (Huber/MSE)
- æ¨¡å‹é€šè¿‡embeddingå±‚å­¦ä¹ è¿™äº›ç‰¹å¾
- å›å½’lossä¼šæŠŠæ•´æ•°å½“è¿ç»­å€¼ä¼˜åŒ–,è¯¯å¯¼å­¦ä¹ 

è¿ç»­ç‰¹å¾ (0-6, 9-10):
- center_x, center_y, vx, vy, ax, ay, angle, has_preceding, has_following
- é€‚åˆå›å½’ä»»åŠ¡
- Huber loss robust to outliers
```

---

### ğŸ“„ `src/training/train_world_model.py`

ä¸»è®­ç»ƒè„šæœ¬ (Transformer-only)ã€‚

#### ä¸»è¦å‡½æ•°

**`parse_args() -> argparse.Namespace`** (L30-56)
- **ä½œç”¨**: è§£æå‘½ä»¤è¡Œå‚æ•°
- **å‚æ•°**:
  - æ•°æ®: `--train_data`, `--val_data`, `--checkpoint_dir`
  - è®­ç»ƒ: `--epochs=50`, `--batch_size=16`, `--lr=3e-4`, `--weight_decay=1e-4`, `--grad_clip=1.0`
  - æ¨¡å‹: `--input_dim=12`, `--max_agents=50`, `--latent_dim=256`
  - Dynamics: `--dynamics_layers=4`, `--dynamics_heads=8`, `--max_dynamics_len=512`, `--max_dynamics_context=128`
  - è®¾å¤‡: `--device` (auto-detect CUDA)

**`save_checkpoint(path, model, optimizer, epoch) -> None`** (L59-68)
- **ä½œç”¨**: ä¿å­˜è®­ç»ƒcheckpoint
- **ä¿å­˜å†…å®¹**:
  ```python
  {
      "epoch": epoch,
      "model_state_dict": model.state_dict(),
      "optimizer_state_dict": optimizer.state_dict()
  }
  ```
- **æ³¨**: normalization statså•ç‹¬ä¿å­˜ä¸º`normalization_stats.npz`

**`evaluate(model, loader, loss_fn, device) -> Dict[str, float]`** (@torch.no_grad(), L71-87)
- **ä½œç”¨**: åœ¨validation setä¸Šè¯„ä¼°
- **æµç¨‹**:
  ```python
  model.eval()
  totals = {"total_loss": 0, "recon_loss": 0, "pred_loss": 0, ...}

  for batch in loader:
      states, masks = batch["states"].to(device), batch["masks"].to(device)
      preds = model(states, masks)
      losses = loss_fn(preds, {"states": states, "masks": masks})

      # ç´¯ç§¯loss
      for k in totals:
          totals[k] += losses[k].item() * batch_size

  # å¹³å‡
  for k in totals:
      totals[k] /= total_samples

  return totals
  ```
- **è¿”å›**: `{total_loss, recon_loss, pred_loss, exist_loss, pred_exist_loss}`

**`main() -> None`** (L90-201)
- **ä½œç”¨**: ä¸»è®­ç»ƒå¾ªç¯
- **æµç¨‹**:

  1. **è§£æå‚æ•°** (L91-94):
     ```python
     args = parse_args()
     ckpt_dir = Path(args.checkpoint_dir)
     ckpt_dir.mkdir(parents=True, exist_ok=True)
     stats_path = ckpt_dir / "normalization_stats.npz"
     ```

  2. **åˆ›å»ºTRAIN DataLoaderå¹¶è®¡ç®—stats** (L96-106):
     ```python
     train_loader = get_dataloader(
         args.train_data,
         batch_size=args.batch_size,
         shuffle=True,
         normalize=True,
         stats_path=None  # â† é¦–æ¬¡è¿è¡Œ,è‡ªåŠ¨è®¡ç®—
     )

     # ä¿å­˜statsä¾›VAL/TESTå¤ç”¨
     if not stats_path.exists():
         train_loader.dataset.save_stats(str(stats_path))
     ```
     **å…³é”®**: åªè®¡ç®—ä¸€æ¬¡stats (ä»TRAIN),VAL/TESTå¤ç”¨!

  3. **åˆ›å»ºVAL DataLoader (å¤ç”¨TRAIN stats)** (L108-116):
     ```python
     val_loader = get_dataloader(
         args.val_data,
         batch_size=args.batch_size,
         shuffle=False,
         normalize=True,
         stats_path=str(stats_path)  # â† ä½¿ç”¨TRAINçš„stats
     )
     ```

  4. **ä»metadataè¯»å–é…ç½®** (L118-123):
     ```python
     meta = train_loader.dataset.metadata
     dt = float(meta.get("dt", 1.0/30.0))
     num_lanes = int(meta.get("num_lanes", 100))
     num_sites = int(meta.get("num_sites", 10))
     num_classes = int(meta.get("num_classes", 10))
     ```

  5. **åˆ›å»ºWorldModel** (L127-140):
     ```python
     model = WorldModel(
         input_dim=args.input_dim,
         max_agents=args.max_agents,
         latent_dim=args.latent_dim,
         dynamics_layers=args.dynamics_layers,
         dynamics_heads=args.dynamics_heads,
         dt=dt,
         max_dynamics_len=args.max_dynamics_len,
         max_dynamics_context=args.max_dynamics_context,
         num_lanes=num_lanes,
         num_sites=num_sites,
         num_classes=num_classes,
         use_acceleration=bool(meta.get("use_acceleration", True)),
     ).to(device)
     ```

  6. **ğŸ”¥ è®¾ç½®normalization statsåˆ°model** (L142-147):
     ```python
     model.set_normalization_stats(
         train_loader.dataset.mean,
         train_loader.dataset.std,
         train_loader.dataset.continuous_indices
     )
     ```
     **å…³é”®**: kinematic prioréœ€è¦è¿™äº›statsæ¥denorm/renorm!

  7. **åˆ›å»ºLosså‡½æ•°** (L149-156):
     ```python
     loss_fn = WorldModelLoss(
         recon_weight=1.0,
         pred_weight=1.0,
         exist_weight=0.1,
         huber_beta=1.0,
         continuous_indices=train_loader.dataset.continuous_indices,  # â† å…³é”®!
         use_pred_existence_loss=True
     )
     ```

  8. **åˆ›å»ºOptimizer** (L158):
     ```python
     optimizer = optim.AdamW(
         model.parameters(),
         lr=args.lr,
         weight_decay=args.weight_decay
     )
     ```

  9. **è®­ç»ƒå¾ªç¯** (L162-199):
     ```python
     best_val = float("inf")

     for epoch in range(args.epochs):
         model.train()
         pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{args.epochs}")
         running_loss = 0.0
         n_samples = 0

         for batch in pbar:
             states = batch["states"].to(device)
             masks = batch["masks"].to(device)

             # Forward
             optimizer.zero_grad(set_to_none=True)
             preds = model(states, masks)
             losses = loss_fn(preds, {"states": states, "masks": masks})
             loss = losses["total_loss"]

             # Backward
             loss.backward()
             if args.grad_clip > 0:
                 clip_grad_norm_(model.parameters(), args.grad_clip)
             optimizer.step()

             # æ›´æ–°è¿›åº¦æ¡
             bs = states.size(0)
             running_loss += loss.item() * bs
             n_samples += bs
             pbar.set_postfix(loss=running_loss / n_samples)

         # Validation
         val_metrics = evaluate(model, val_loader, loss_fn, device)
         val_loss = val_metrics["total_loss"]

         # æ‰“å°
         print(f"[Epoch {epoch+1}] train_loss={running_loss/n_samples:.4f}  "
               f"val_loss={val_loss:.4f}  recon={val_metrics['recon_loss']:.4f} "
               f"pred={val_metrics['pred_loss']:.4f} exist={val_metrics['exist_loss']:.4f} "
               f"pred_exist={val_metrics['pred_exist_loss']:.4f}")

         # ä¿å­˜checkpoints
         save_checkpoint(ckpt_dir / "checkpoint_last.pt", model, optimizer, epoch)

         if val_loss < best_val:
             best_val = val_loss
             save_checkpoint(ckpt_dir / "checkpoint_best.pt", model, optimizer, epoch)

     print("Training finished.")
     ```

**è®­ç»ƒè¾“å‡ºç¤ºä¾‹**:
```
[Epoch 1] train_loss=12.3456  val_loss=13.4567  recon=10.234 pred=2.345 exist=0.123 pred_exist=0.098
[Epoch 2] train_loss=10.1234  val_loss=11.2345  recon=8.456 pred=1.987 exist=0.112 pred_exist=0.089
...
[Epoch 50] train_loss=3.4567  val_loss=4.1234  recon=2.345 pred=0.987 exist=0.098 pred_exist=0.087
```

**å®Œæ•´è®­ç»ƒå‘½ä»¤ç¤ºä¾‹**:
```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --checkpoint_dir checkpoints/world_model \
    --input_dim 12 \
    --latent_dim 256 \
    --dynamics_layers 4 \
    --dynamics_heads 8 \
    --batch_size 16 \
    --epochs 50 \
    --lr 3e-4 \
    --weight_decay 1e-4 \
    --grad_clip 1.0
```

**å…³é”®è®¾è®¡**:
1. âœ… **ONE normalization stats**: åªä»TRAINè®¡ç®—,VAL/TESTå¤ç”¨
2. âœ… **Continuous indices**: ä¼ é€’ç»™loss,ç¡®ä¿åªå›å½’è¿ç»­ç‰¹å¾
3. âœ… **Normalization statsè®¾ç½®åˆ°model**: kinematic prioréœ€è¦
4. âœ… **Transformer-only**: ç§»é™¤GRU/LSTMé€‰é¡¹,ç®€åŒ–æ¶æ„
5. âœ… **Gradient clipping**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ (clip_norm=1.0)
6. âœ… **AdamW optimizer**: weight decay regularization

---

---

## è¯„ä¼°æ¨¡å— (ç»­)

### ğŸ“„ `src/evaluation/rollout_eval.py`

(å¾…è¯»å–å¹¶è¡¥å……)

### ğŸ“„ `src/evaluation/prediction_metrics.py`

(å¾…è¯»å–å¹¶è¡¥å……)

---

## é™„å½•

### ç‰¹å¾å¸ƒå±€ (12ç»´)

```
[0]  center_x         â†’ continuous (z-score)
[1]  center_y         â†’ continuous (z-score)
[2]  vx               â†’ continuous
[3]  vy               â†’ continuous
[4]  ax               â†’ continuous
[5]  ay               â†’ continuous
[6]  angle            â†’ continuous
[7]  class_id         â†’ discrete (DO NOT normalize, use embedding)
[8]  lane_id          â†’ discrete (DO NOT normalize, use embedding)
[9]  has_preceding    â†’ continuous (binary 0/1)
[10] has_following    â†’ continuous (binary 0/1)
[11] site_id          â†’ discrete (DO NOT normalize, use embedding)
```

### é‡è¦å¸¸é‡

- **FPS**: 30.0 (å¸§ç‡)
- **dt**: 1/30 â‰ˆ 0.0333 ç§’ (æ—¶é—´æ­¥é•¿)
- **T**: 80 å¸§ (episodeé•¿åº¦, ~2.67ç§’)
- **C**: 65 å¸§ (contexté•¿åº¦, ~2.17ç§’)
- **H**: 15 å¸§ (rollout horizon, ~0.50ç§’)
- **S (stride)**: 15 å¸§ (episodeé—´éš”, ~0.50ç§’)
- **K (max_vehicles)**: 50
- **F (n_features)**: 12

### æ•°æ®æµ

```
åŸå§‹CSVæ–‡ä»¶
  â†“ (preprocess_multisite.py)
å…¨å±€æ—¶é—´çº¿ â†’ è¿ç»­æ®µæ£€æµ‹ â†’ å›ºå®šstride episodes
  â†“
NPZæ–‡ä»¶ [N, T=80, K=50, F=12]
  â†“ (dataset.py)
å½’ä¸€åŒ– (continuous only) + Discrete validation
  â†“ (DataLoader)
Batch [B, T, K, F]
  â†“ (WorldModel)
Encoder â†’ Transformer Dynamics â†’ Decoder (+ Kinematic Prior)
  â†“
é¢„æµ‹states [B, T, K, F]
```

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2025-12-14
**é¡¹ç›®ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: éƒ¨åˆ†å®Œæˆ (æ¨¡å‹ã€è®­ç»ƒã€è¯„ä¼°æ¨¡å—å¾…è¡¥å……)
