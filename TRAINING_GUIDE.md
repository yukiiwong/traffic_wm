# World Model è®­ç»ƒå‚æ•°è°ƒèŠ‚æŒ‡å—

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å‚æ•°å®Œæ•´åˆ—è¡¨](#å‚æ•°å®Œæ•´åˆ—è¡¨)
- [å‚æ•°è°ƒèŠ‚ç­–ç•¥](#å‚æ•°è°ƒèŠ‚ç­–ç•¥)
- [å¸¸è§åœºæ™¯é…ç½®](#å¸¸è§åœºæ™¯é…ç½®)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## å¿«é€Ÿå¼€å§‹

### åŸºç¡€è®­ç»ƒå‘½ä»¤

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --batch_size 32 \
    --n_epochs 100 \
    --latent_dim 256
```

---

## å‚æ•°å®Œæ•´åˆ—è¡¨

### 1. æ•°æ®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒèŠ‚å»ºè®® |
|-----|-------|------|---------|
| `--train_data` | **å¿…éœ€** | è®­ç»ƒæ•°æ®è·¯å¾„ | `data/processed/train_episodes.npz` |
| `--val_data` | None | éªŒè¯æ•°æ®è·¯å¾„ | `data/processed/val_episodes.npz` |
| `--num_workers` | 4 | æ•°æ®åŠ è½½çº¿ç¨‹æ•° | CPUæ ¸å¿ƒæ•°çš„ä¸€åŠ |

---

### 2. æ¨¡å‹æ¶æ„å‚æ•° â­ é‡è¦

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒèŠ‚å»ºè®® |
|-----|-------|------|---------|
| `--input_dim` | 10 | æ¯ä¸ªagentçš„ç‰¹å¾æ•° | 6 (åŸºç¡€) æˆ– 10 (æ‰©å±•) |
| `--max_agents` | 50 | æ¯å¸§æœ€å¤§è½¦è¾†æ•° | ä¸é¢„å¤„ç†æ—¶ä¸€è‡´ |
| `--latent_dim` | 256 | æ½œåœ¨ç©ºé—´ç»´åº¦ | ğŸ”¥ **å…³é”®å‚æ•°** è§ä¸‹æ–¹ |
| `--dynamics_type` | 'gru' | åŠ¨æ€æ¨¡å‹ç±»å‹ | gru/lstm/transformer |

#### latent_dim è°ƒèŠ‚æŒ‡å—

- **128**: å°æ¨¡å‹ï¼Œè®­ç»ƒå¿«ï¼Œé€‚åˆå¿«é€Ÿå®éªŒ
- **256**: â­ **æ¨è**ï¼Œå¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦
- **512**: å¤§æ¨¡å‹ï¼Œæ€§èƒ½æ›´å¥½ï¼Œä½†éœ€è¦æ›´å¤šå†…å­˜å’Œæ—¶é—´
- **1024**: è¶…å¤§æ¨¡å‹ï¼Œä»…åœ¨æ•°æ®é‡å……è¶³æ—¶ä½¿ç”¨

#### dynamics_type é€‰æ‹©

| ç±»å‹ | é€Ÿåº¦ | æ€§èƒ½ | æ˜¾å­˜å ç”¨ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|---------|
| `gru` | â­â­â­ | â­â­ | ä½ | å¿«é€Ÿå®éªŒï¼Œèµ„æºå—é™ |
| `lstm` | â­â­ | â­â­â­ | ä¸­ | éœ€è¦é•¿æœŸä¾èµ– |
| `transformer` | â­ | â­â­â­â­ | é«˜ | è¿½æ±‚æœ€ä½³æ€§èƒ½ |

---

### 3. è®­ç»ƒå‚æ•° ğŸ¯ æ ¸å¿ƒ

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒèŠ‚å»ºè®® |
|-----|-------|------|---------|
| `--batch_size` | 32 | æ‰¹æ¬¡å¤§å° | ğŸ”¥ **å…³é”®å‚æ•°** è§ä¸‹æ–¹ |
| `--n_epochs` | 100 | è®­ç»ƒè½®æ•° | 100-300 epochs |
| `--learning_rate` | 1e-3 | å­¦ä¹ ç‡ | ğŸ”¥ **å…³é”®å‚æ•°** è§ä¸‹æ–¹ |
| `--weight_decay` | 1e-5 | æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰ | 1e-5 ~ 1e-4 |

#### batch_size è°ƒèŠ‚æŒ‡å—

**å½±å“å› ç´ ï¼š**
- GPUæ˜¾å­˜å¤§å°
- è®­ç»ƒç¨³å®šæ€§
- è®­ç»ƒé€Ÿåº¦

**æ¨èå€¼ï¼š**
- **8-16**: å°æ˜¾å­˜GPUï¼ˆ4GBï¼‰
- **32**: â­ æ¨èï¼Œä¸­ç­‰GPUï¼ˆ8GBï¼‰
- **64**: å¤§æ˜¾å­˜GPUï¼ˆ16GB+ï¼‰
- **128**: è¶…å¤§æ˜¾å­˜ï¼ˆ24GB+ï¼‰ï¼Œæ•°æ®å……è¶³

**æ³¨æ„ï¼š** batch_size è¶Šå¤§ï¼Œè®­ç»ƒè¶Šç¨³å®šï¼Œä½†éœ€è¦æ›´å¤šæ˜¾å­˜

#### learning_rate è°ƒèŠ‚æŒ‡å—

**é»˜è®¤é…ç½®ï¼š**
```
åˆå§‹å­¦ä¹ ç‡: 1e-3 (0.001)
è°ƒåº¦å™¨: CosineAnnealingLR
æœ€å°å­¦ä¹ ç‡: 1e-6
```

**æ¨èå€¼ï¼š**
- **3e-4**: â­ **æœ€ä¿é™©**ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
- **1e-3**: é»˜è®¤å€¼ï¼Œè®­ç»ƒå¿«ä½†å¯èƒ½ä¸ç¨³å®š
- **5e-4**: å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§
- **1e-4**: æ…¢ä½†ç¨³å®šï¼Œé€‚åˆå¾®è°ƒ

**è°ƒèŠ‚ç­–ç•¥ï¼š**
1. å¦‚æœlosséœ‡è¡ â†’ é™ä½å­¦ä¹ ç‡
2. å¦‚æœæ”¶æ•›å¤ªæ…¢ â†’ æé«˜å­¦ä¹ ç‡
3. å¦‚æœåœ¨æœ€ä¼˜ç‚¹é™„è¿‘éœ‡è¡ â†’ é™ä½æœ€å°å­¦ä¹ ç‡

---

### 4. æŸå¤±å‡½æ•°æƒé‡ âš–ï¸

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒèŠ‚å»ºè®® |
|-----|-------|------|---------|
| `--recon_weight` | 1.0 | é‡å»ºæŸå¤±æƒé‡ | ä¿æŒ1.0ä½œä¸ºåŸºå‡† |
| `--pred_weight` | 1.0 | é¢„æµ‹æŸå¤±æƒé‡ | 1.0 ~ 2.0 |
| `--existence_weight` | 0.1 | å­˜åœ¨æ€§æŸå¤±æƒé‡ | 0.1 ~ 0.5 |

#### æŸå¤±æƒé‡è°ƒèŠ‚ç­–ç•¥

**åœºæ™¯1: æ¨¡å‹é‡å»ºå¥½ä½†é¢„æµ‹å·®**
```bash
--recon_weight 1.0 \
--pred_weight 2.0 \      # å¢åŠ é¢„æµ‹æƒé‡
--existence_weight 0.1
```

**åœºæ™¯2: è½¦è¾†å‡ºç°/æ¶ˆå¤±é¢„æµ‹ä¸å‡†**
```bash
--recon_weight 1.0 \
--pred_weight 1.0 \
--existence_weight 0.5   # å¢åŠ å­˜åœ¨æ€§æƒé‡
```

**åœºæ™¯3: å¹³è¡¡é…ç½®ï¼ˆæ¨èï¼‰**
```bash
--recon_weight 1.0 \
--pred_weight 1.5 \
--existence_weight 0.2
```

---

### 5. å…¶ä»–å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|-----|-------|------|
| `--seed` | 42 | éšæœºç§å­ |
| `--checkpoint_dir` | './checkpoints' | æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½• |
| `--log_dir` | './logs' | æ—¥å¿—ä¿å­˜ç›®å½• |
| `--resume` | None | ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ |

---

## å‚æ•°è°ƒèŠ‚ç­–ç•¥

### é˜¶æ®µ1: å¿«é€ŸåŸå‹ï¼ˆ1-2å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** éªŒè¯æ•°æ®å’Œä»£ç æ˜¯å¦æ­£å¸¸

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 10 \
    --max_agents 50 \
    --latent_dim 128 \              # å°æ¨¡å‹
    --dynamics_type gru \           # å¿«é€Ÿ
    --batch_size 32 \
    --n_epochs 10 \                 # å°‘é‡epochs
    --learning_rate 1e-3
```

**æœŸæœ›ç»“æœï¼š**
- è®­ç»ƒlossä¸‹é™
- éªŒè¯lossä¸‹é™
- æ²¡æœ‰NaNæˆ–çˆ†ç‚¸

---

### é˜¶æ®µ2: åŸºå‡†æµ‹è¯•ï¼ˆ4-8å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** è·å¾—åŸºå‡†æ€§èƒ½

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 10 \
    --max_agents 50 \
    --latent_dim 256 \              # æ ‡å‡†å¤§å°
    --dynamics_type gru \
    --batch_size 32 \
    --n_epochs 100 \                # å®Œæ•´è®­ç»ƒ
    --learning_rate 3e-4 \          # ä¿å®ˆå­¦ä¹ ç‡
    --recon_weight 1.0 \
    --pred_weight 1.5 \
    --existence_weight 0.2
```

**æœŸæœ›ç»“æœï¼š**
- ADE < 5.0m (1sé¢„æµ‹)
- FDE < 10.0m (3sé¢„æµ‹)
- è®­ç»ƒç¨³å®š

---

### é˜¶æ®µ3: æ€§èƒ½ä¼˜åŒ–ï¼ˆ1-3å¤©ï¼‰

**ç›®æ ‡ï¼š** è·å¾—æœ€ä½³æ€§èƒ½

#### æ–¹æ¡ˆA: å¢å¤§æ¨¡å‹å®¹é‡

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 10 \
    --latent_dim 512 \              # å¤§æ¨¡å‹
    --dynamics_type transformer \   # æ›´å¼ºçš„æ¨¡å‹
    --batch_size 64 \               # æ›´å¤§batch
    --n_epochs 200 \
    --learning_rate 3e-4
```

#### æ–¹æ¡ˆB: è°ƒæ•´æŸå¤±æƒé‡

```bash
# å¤šæ¬¡å®éªŒï¼Œå°è¯•ä¸åŒæƒé‡ç»„åˆ
python src/training/train_world_model.py \
    ... \
    --recon_weight 1.0 \
    --pred_weight 2.0 \             # æ›´é‡è§†é¢„æµ‹
    --existence_weight 0.3
```

#### æ–¹æ¡ˆC: å­¦ä¹ ç‡è°ƒä¼˜

```bash
# å®éªŒ1: è¾ƒå¤§å­¦ä¹ ç‡
python src/training/train_world_model.py \
    ... \
    --learning_rate 1e-3

# å®éªŒ2: è¾ƒå°å­¦ä¹ ç‡
python src/training/train_world_model.py \
    ... \
    --learning_rate 1e-4

# å®éªŒ3: ä¸­ç­‰å­¦ä¹ ç‡ï¼ˆé€šå¸¸æœ€å¥½ï¼‰
python src/training/train_world_model.py \
    ... \
    --learning_rate 5e-4
```

---

## å¸¸è§åœºæ™¯é…ç½®

### åœºæ™¯1: èµ„æºå—é™ï¼ˆå°GPUï¼‰

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 10 \
    --latent_dim 128 \
    --dynamics_type gru \
    --batch_size 8 \                # å°batch
    --n_epochs 150 \
    --learning_rate 3e-4
```

---

### åœºæ™¯2: è¿½æ±‚é€Ÿåº¦

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --input_dim 6 \                 # ä½¿ç”¨åŸºç¡€ç‰¹å¾
    --latent_dim 128 \
    --dynamics_type gru \
    --batch_size 64 \               # å¤§batchåŠ é€Ÿ
    --n_epochs 50 \                 # å°‘é‡epochs
    --num_workers 8
```

---

### åœºæ™¯3: è¿½æ±‚æ€§èƒ½

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --input_dim 10 \                # æ‰©å±•ç‰¹å¾
    --latent_dim 512 \              # å¤§æ¨¡å‹
    --dynamics_type transformer \   # å¼ºæ¨¡å‹
    --batch_size 32 \
    --n_epochs 300 \                # å……åˆ†è®­ç»ƒ
    --learning_rate 3e-4 \
    --recon_weight 1.0 \
    --pred_weight 2.0 \
    --existence_weight 0.3
```

---

### åœºæ™¯4: é•¿æœŸé¢„æµ‹

```bash
python src/training/train_world_model.py \
    --train_data data/processed/train_episodes.npz \
    --val_data data/processed/val_episodes.npz \
    --latent_dim 512 \
    --dynamics_type lstm \          # LSTMé€‚åˆé•¿æœŸä¾èµ–
    --pred_weight 3.0 \             # éå¸¸é‡è§†é¢„æµ‹
    --n_epochs 200
```

---

## æ€§èƒ½ä¼˜åŒ–

### GPUä¼˜åŒ–

1. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   - å¯åŠ é€Ÿ2-3å€
   - å‡å°‘50%æ˜¾å­˜å ç”¨

2. **å¢å¤§batch_size**
   - å……åˆ†åˆ©ç”¨GPUå¹¶è¡Œèƒ½åŠ›
   - æé«˜è®­ç»ƒç¨³å®šæ€§

3. **å¤šGPUè®­ç»ƒ**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   - ä½¿ç”¨ DataParallel æˆ– DistributedDataParallel

### æ•°æ®åŠ è½½ä¼˜åŒ–

```bash
--num_workers 8  # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
```

### è¶…å‚æ•°æœç´¢

åˆ›å»ºä¸€ä¸ªè„šæœ¬å°è¯•ä¸åŒç»„åˆï¼š

```bash
# search_hyperparams.sh
for lr in 1e-3 5e-4 3e-4 1e-4; do
  for latent_dim in 128 256 512; do
    python src/training/train_world_model.py \
        --train_data data/processed/train_episodes.npz \
        --val_data data/processed/val_episodes.npz \
        --latent_dim $latent_dim \
        --learning_rate $lr \
        --n_epochs 100 \
        --checkpoint_dir checkpoints/lr_${lr}_dim_${latent_dim}
  done
done
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜1: Lossæ˜¯NaN

**åŸå› ï¼š** å­¦ä¹ ç‡è¿‡å¤§ï¼Œæ¢¯åº¦çˆ†ç‚¸

**è§£å†³ï¼š**
```bash
--learning_rate 1e-4  # é™ä½å­¦ä¹ ç‡
```

---

### é—®é¢˜2: Lossä¸ä¸‹é™

**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**

1. **å­¦ä¹ ç‡å¤ªå°**
   ```bash
   --learning_rate 1e-3  # æé«˜å­¦ä¹ ç‡
   ```

2. **æ¨¡å‹å®¹é‡ä¸è¶³**
   ```bash
   --latent_dim 512  # å¢å¤§æ¨¡å‹
   ```

3. **æ•°æ®é—®é¢˜**
   - æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®åŠ è½½
   - æ£€æŸ¥æ•°æ®æ˜¯å¦å½’ä¸€åŒ–

---

### é—®é¢˜3: è®­ç»ƒ/éªŒè¯Losså·®è·å¤§ï¼ˆè¿‡æ‹Ÿåˆï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å¢åŠ æ­£åˆ™åŒ–**
   ```bash
   --weight_decay 1e-4  # å¢åŠ æƒé‡è¡°å‡
   ```

2. **å‡å°æ¨¡å‹**
   ```bash
   --latent_dim 128
   ```

3. **æ—©åœ**
   - ç›‘æ§éªŒè¯lossï¼ŒåŠæ—¶åœæ­¢

---

### é—®é¢˜4: æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å‡å°batch_size**
   ```bash
   --batch_size 16  # æˆ–æ›´å°
   ```

2. **å‡å°æ¨¡å‹**
   ```bash
   --latent_dim 128
   ```

3. **ä½¿ç”¨GRUè€Œä¸æ˜¯Transformer**
   ```bash
   --dynamics_type gru
   ```

---

### é—®é¢˜5: è®­ç»ƒå¤ªæ…¢

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å¢å¤§batch_size**
   ```bash
   --batch_size 64
   ```

2. **å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹**
   ```bash
   --num_workers 8
   ```

3. **ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹**
   ```bash
   --dynamics_type gru
   --latent_dim 128
   ```

---

## ç›‘æ§è®­ç»ƒè¿›åº¦

### æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/trainer.log

# æœç´¢æœ€ä½³éªŒè¯loss
grep "Val Loss" logs/trainer.log | sort -k6 -n | head -5
```

### ä½¿ç”¨TensorBoardï¼ˆéœ€è¦æ·»åŠ ï¼‰

å¦‚æœåç»­æ·»åŠ TensorBoardæ”¯æŒï¼š

```bash
tensorboard --logdir logs/
```

---

## æ¨èå®éªŒæµç¨‹

```
1. å¿«é€ŸåŸå‹ï¼ˆlatent_dim=128, 10 epochsï¼‰
   â””â”€> éªŒè¯ä»£ç å’Œæ•°æ®æ­£å¸¸

2. åŸºå‡†å®éªŒï¼ˆlatent_dim=256, 100 epochs, lr=3e-4ï¼‰
   â””â”€> è·å¾—åŸºå‡†ADE/FDE

3. å­¦ä¹ ç‡æ‰«æï¼ˆlr in [1e-4, 3e-4, 5e-4, 1e-3]ï¼‰
   â””â”€> æ‰¾åˆ°æœ€ä½³å­¦ä¹ ç‡

4. æ¨¡å‹å¤§å°æ‰«æï¼ˆlatent_dim in [128, 256, 512]ï¼‰
   â””â”€> å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦

5. æŸå¤±æƒé‡è°ƒä¼˜ï¼ˆpred_weight in [1.0, 1.5, 2.0, 3.0]ï¼‰
   â””â”€> ä¼˜åŒ–é¢„æµ‹æ€§èƒ½

6. æœ€ç»ˆè®­ç»ƒï¼ˆæœ€ä½³é…ç½®, 200-300 epochsï¼‰
   â””â”€> è·å¾—æœ€ä½³æ¨¡å‹
```

---

## å‚æ•°é€ŸæŸ¥è¡¨

| ç›®æ ‡ | æ¨èé…ç½® |
|-----|---------|
| å¿«é€Ÿå®éªŒ | `latent_dim=128, batch_size=32, n_epochs=10` |
| åŸºå‡†æµ‹è¯• | `latent_dim=256, lr=3e-4, n_epochs=100` |
| æœ€ä½³æ€§èƒ½ | `latent_dim=512, dynamics=transformer, n_epochs=300` |
| èµ„æºå—é™ | `latent_dim=128, batch_size=8, dynamics=gru` |
| é•¿æœŸé¢„æµ‹ | `dynamics=lstm, pred_weight=3.0` |

---

**æœ€åæ›´æ–°:** 2025-12-09
**ç‰ˆæœ¬:** 1.0
