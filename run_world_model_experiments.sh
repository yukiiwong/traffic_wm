#!/usr/bin/env bash
set -euo pipefail

# ========= åŸºæœ¬è·¯å¾„è®¾ç½® =========
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_ROOT"

TRAIN_SCRIPT="src/training/train_world_model.py"

TRAIN_DATA="data/processed/train_episodes.npz"
VAL_DATA="data/processed/val_episodes.npz"

LOG_DIR="logs/world_model"
CKPT_DIR="checkpoints/world_model"

mkdir -p "$LOG_DIR" "$CKPT_DIR"

# ========= å›ºå®šå‚æ•°ï¼ˆå¯ä»¥æŒ‰éœ€æ”¹ï¼‰ =========
INPUT_DIM=11              # å’Œ metadata.json é‡Œçš„ n_features ä¸€è‡´
BATCH_SIZE=128
N_EPOCHS=200
LR=3e-4

ENCODER_HIDDEN=128
DYNAMICS_HIDDEN=512
LATENT_DIMS=(256 512)     # å¯¹æ¯”ä¸¤ä¸ª latent dim

# æ”¯æŒçš„ dynamics_typeï¼šgru / lstm / transformer
DYNAMICS_TYPES=("gru" "lstm" "transformer")

# å¤šéšæœºç§å­ï¼ˆå¯é€‰ï¼‰
SEEDS=(1 2 3)

# æ§åˆ¶å¹¶è¡Œæ•°ï¼ˆæ¯”å¦‚åŒæ—¶è·‘ 3 ä¸ªå®éªŒï¼Œå¦‚æœä½ æƒ³å…¨éƒ¨ä¸²è¡Œï¼Œå°±è®¾æˆ 1ï¼‰
MAX_JOBS=3

# ========= ä¸€ä¸ªå°å‡½æ•°ï¼šé™åˆ¶å¹¶è¡Œä»»åŠ¡æ•° =========
wait_for_free_slot() {
  while true; do
    # ç»Ÿè®¡å½“å‰åå°è¿è¡Œçš„ä»»åŠ¡æ•°
    local njobs
    njobs=$(jobs -r | wc -l)
    if (( njobs < MAX_JOBS )); then
      break
    fi
    sleep 5
  done
}

# ========= ä¸»å¾ªç¯ï¼šæ‰«æ‰€æœ‰ç»„åˆ =========
for dyn in "${DYNAMICS_TYPES[@]}"; do
  for latent in "${LATENT_DIMS[@]}"; do
    for seed in "${SEEDS[@]}"; do

      EXP_NAME="dyn_${dyn}_z${latent}_seed${seed}"
      LOG_FILE="${LOG_DIR}/${EXP_NAME}.log"
      CKPT_SUBDIR="${CKPT_DIR}/${EXP_NAME}"
      mkdir -p "$CKPT_SUBDIR"

      echo "â–¶ Starting experiment: ${EXP_NAME}"
      echo "  dynamics_type=${dyn}, latent_dim=${latent}, seed=${seed}"
      echo "  logs:   ${LOG_FILE}"
      echo "  ckpt:   ${CKPT_SUBDIR}"

      wait_for_free_slot

      CUDA_VISIBLE_DEVICES=0 \
      python "$TRAIN_SCRIPT" \
        --train_data "$TRAIN_DATA" \
        --val_data   "$VAL_DATA" \
        --input_dim  "$INPUT_DIM" \
        --latent_dim "$latent" \
        --encoder_hidden  "$ENCODER_HIDDEN" \
        --dynamics_hidden "$DYNAMICS_HIDDEN" \
        --dynamics_type   "$dyn" \
        --batch_size  "$BATCH_SIZE" \
        --n_epochs    "$N_EPOCHS" \
        --learning_rate "$LR" \
        --seed        "$seed" \
        --output_dir  "$CKPT_SUBDIR" \
        >"$LOG_FILE" 2>&1 &

      # å»æ‰ä¸Šé¢çš„ & åˆ™æ”¹ä¸ºä¸²è¡Œè¿è¡Œ

    done
  done
done

echo "ğŸ‰ All experiments submitted. Use 'jobs -l' to check running status."
